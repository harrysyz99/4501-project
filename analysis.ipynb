{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "offset = 0\n",
    "start_date_str = start_date.strftime(date_format)\n",
    "end_date_str = end_date.strftime(date_format)\n",
    "date_query = f\"$where={date_field} between '{start_date_str}' and '{end_date_str}'\"\n",
    "\n",
    "# set up as the first batch\n",
    "first_batch = True\n",
    "while True:\n",
    "    full_url = f\"{url}?$$app_token={app_token}&{date_query}&$limit={limit}&$offset={offset}\"\n",
    "    response = requests.get(full_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-07T20:53:19.410290300Z",
     "start_time": "2023-12-07T20:53:19.381290600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from typing import List, Union, Set\n",
    "def read_shapefile(shapefile_path: str) -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Reads the shapefile into a GeoDataFrame.\n",
    "\n",
    "    Args:\n",
    "    - shapefile_path (str): Path to the shapefile.\n",
    "\n",
    "    Returns:\n",
    "    - gpd.GeoDataFrame: The GeoDataFrame read from the shapefile.\n",
    "    \"\"\"\n",
    "    return gpd.read_file(shapefile_path)\n",
    "\n",
    "def filter_columns(gdf: gpd.GeoDataFrame, columns: List[str]) -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Filters the GeoDataFrame to include only specified columns.\n",
    "\n",
    "    Args:\n",
    "    - gdf (gpd.GeoDataFrame): The original GeoDataFrame.\n",
    "    - columns (List[str]): A list of column names to retain.\n",
    "\n",
    "    Returns:\n",
    "    - gpd.GeoDataFrame: The GeoDataFrame with only the specified columns.\n",
    "    \"\"\"\n",
    "    return gdf[columns]\n",
    "\n",
    "def remove_duplicates(gdf: gpd.GeoDataFrame, subset: str) -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Removes duplicate rows based on a specified subset of columns.\n",
    "\n",
    "    Args:\n",
    "    - gdf (gpd.GeoDataFrame): The GeoDataFrame to process.\n",
    "    - subset (str): Column name to check for duplicates.\n",
    "\n",
    "    Returns:\n",
    "    - gpd.GeoDataFrame: The GeoDataFrame with duplicates removed.\n",
    "    \"\"\"\n",
    "    return gdf.drop_duplicates(subset=[subset])\n",
    "\n",
    "def filter_invalid_zipcodes(gdf: gpd.GeoDataFrame) -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Keeps only rows with valid 5-digit zipcodes.\n",
    "\n",
    "    Args:\n",
    "    - gdf (gpd.GeoDataFrame): The GeoDataFrame to process.\n",
    "\n",
    "    Returns:\n",
    "    - gpd.GeoDataFrame: The GeoDataFrame with only valid 5-digit zipcodes.\n",
    "    \"\"\"\n",
    "    gdf['zipcode'] = gdf['zipcode'].astype(str)\n",
    "    return gdf[gdf['zipcode'].str.isdigit() & (gdf['zipcode'].str.len() == 5)]\n",
    "\n",
    "def process_zipcode_shapefile(shapefile_path: str) -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Cleans and prepares a zipcode shapefile for analysis.\n",
    "\n",
    "    Args:\n",
    "    - shapefile_path (str): Path to the zipcode shapefile.\n",
    "\n",
    "    Returns:\n",
    "    - gpd.GeoDataFrame: GeoDataFrame with processed zipcode data.\n",
    "    \"\"\"\n",
    "    zipcode_gdf = read_shapefile(shapefile_path)\n",
    "    essential_columns = ['ZIPCODE', 'geometry']\n",
    "    zipcode_gdf = filter_columns(zipcode_gdf, essential_columns)\n",
    "    zipcode_gdf = remove_duplicates(zipcode_gdf, 'ZIPCODE')\n",
    "    zipcode_gdf.dropna(subset=essential_columns, inplace=True)\n",
    "    zipcode_gdf.rename(columns={'ZIPCODE': 'zipcode'}, inplace=True)\n",
    "    zipcode_gdf = filter_invalid_zipcodes(zipcode_gdf)\n",
    "    common_crs = \"EPSG:3857\"\n",
    "    zipcode_gdf.to_crs(common_crs, inplace=True)\n",
    "    zipcode_gdf.columns = map(str.lower, zipcode_gdf.columns)\n",
    "\n",
    "    return zipcode_gdf\n",
    "\n",
    "def lat_validation(latitude):\n",
    "    if not isinstance(latitude, (int, float)):\n",
    "        raise TypeError(\"The latitude should be a float or int type\")\n",
    "    return -90 <= latitude <= 90\n",
    "\n",
    "\n",
    "def long_validation(longitude: float) -> bool:\n",
    "    if not isinstance(longitude, (int, float)):\n",
    "        raise TypeError(\"The longitude should be a float or int type\")\n",
    "    return -180 <= longitude <= 180\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-07T21:28:24.550350100Z",
     "start_time": "2023-12-07T21:28:24.400244400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "geodf_zip_data = process_zipcode_shapefile(\"data/nyc_zipcodes/nyc_zipcodes.shp\")\n",
    "nyc_zips = geodf_zipcode_data['zipcode'].tolist()\n",
    "nyc_zips = [float(element) for element in nyc_zips]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-07T21:28:25.650922700Z",
     "start_time": "2023-12-07T21:28:25.639922Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "columns_needed = ['Unique Key', 'Created Date', 'Complaint Type', 'Incident Zip', 'Latitude', 'Longitude', 'Location']\n",
    "def filter_t311(df: pd.DataFrame, column_needed: List[str], nyc_zip: Union[Set[str], List[str]]) -> gpd.GeoDataFrame:\n",
    "    # Filter the DataFrame to only include necessary columns and drop rows with NaN values\n",
    "    filtered = df[column_needed].dropna()\n",
    "\n",
    "    # Further filter the DataFrame to only include rows where 'Incident Zip' is in nyc_zip\n",
    "    filtered = filtered[filtered['Incident Zip'].isin(nyc_zip)]\n",
    "\n",
    "    # Converting 'Created Date' to datetime\n",
    "    filtered['Created Date'] = pd.to_datetime(filtered['Created Date'])\n",
    "\n",
    "    # Define your date range\n",
    "    start_date = pd.to_datetime('2015-01-01')\n",
    "    end_date = pd.to_datetime('2023-09-30')\n",
    "\n",
    "    # Filter the DataFrame for dates within the range\n",
    "    filtered = filtered[(filtered['Created Date'] >= start_date) & (filtered['Created Date'] <= end_date)]\n",
    "\n",
    "    # Apply latitude and longitude validation\n",
    "    filtered = filtered[filtered['Latitude'].apply(lat_validation) & filtered['Longitude'].apply(long_validation)]\n",
    "\n",
    "    # Convert to GeoDataFrame\n",
    "    filtered = gpd.GeoDataFrame(filtered, geometry=gpd.points_from_xy(filtered['Longitude'], filtered['Latitude']))\n",
    "    filtered.set_crs(\"EPSG:4326\", inplace=True)\n",
    "    filtered.to_crs(\"EPSG:3857\", inplace=True)\n",
    "\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-07T22:46:21.680787600Z",
     "start_time": "2023-12-07T22:46:21.660278Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "## cehck\n",
    "def filter_stc(df: pd.DataFrame, column_needed: List[str], nyc_zip: Set[str]) -> gpd.GeoDataFrame:\n",
    "    # Filter the DataFrame to only include necessary columns and drop rows with NaN values\n",
    "    filtered = df[columns_needed].dropna()\n",
    "\n",
    "    # Further filter the DataFrame to only include rows where 'zipcode' is in nyc_zip\n",
    "    filtered = filtered[filtered['zipcode'].isin(nyc_zip)]\n",
    "\n",
    "    # Converting 'created_at' to datetime\n",
    "    filtered['created_at'] = pd.to_datetime(filtered['created_at'])\n",
    "\n",
    "    # Define your date range\n",
    "    start_date = pd.to_datetime('01/01/2015')\n",
    "    end_date = pd.to_datetime('09/30/2023')  # Corrected date\n",
    "\n",
    "    # Filter the DataFrame for dates within the range\n",
    "    filtered = filtered[(filtered['created_at'] >= start_date) & (filtered['created_at'] <= end_date)]\n",
    "\n",
    "    # Apply latitude and longitude validation\n",
    "    filtered = filtered[filtered['Latitude'].apply(lat_validation) & filtered['longitude'].apply(long_validation)]\n",
    "\n",
    "    # Convert to GeoDataFrame\n",
    "    filtered = gpd.GeoDataFrame(filtered, geometry=gpd.points_from_xy(filtered['longitude'], filtered['Latitude']))\n",
    "    filtered.set_crs(\"EPSG:4326\", inplace=True)\n",
    "    filtered.to_crs(\"EPSG:3857\", inplace=True)\n",
    "\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-07T22:53:12.667296300Z",
     "start_time": "2023-12-07T22:53:12.655296400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def filter_zillow(df: pd.DataFrame, nyc_zip: list) -> pd.DataFrame:\n",
    "    # Selecting the required columns. Assuming the first column is 'RegionName' and the 9th to last are dates\n",
    "    useful_cols = df.columns[9:].to_list() + ['RegionName']\n",
    "    filtered = df[useful_cols]\n",
    "\n",
    "    # Drop rows where 'RegionName' is NaN\n",
    "    filtered = filtered.dropna(subset=['RegionName'])\n",
    "\n",
    "    # Filter rows where 'RegionName' is in the list of NYC zip codes\n",
    "    filtered = filtered[filtered['RegionName'].isin(nyc_zip)]\n",
    "\n",
    "    # Melting the DataFrame\n",
    "    melted_df = filtered.melt(id_vars=['RegionName'], var_name='Date', value_name='Value')\n",
    "\n",
    "    return melted_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-07T23:24:05.792010Z",
     "start_time": "2023-12-07T23:24:05.383975900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdf\\AppData\\Local\\Temp\\ipykernel_20368\\4019357403.py:1: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  a = pd.read_csv(\"data/Bedbug_Reporting_20231203.csv\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Building ID', 'Registration ID', 'Borough', 'House Number',\n",
       "       'Street Name', 'Postcode', '# of Dwelling Units',\n",
       "       'Infested Dwelling Unit Count', 'Eradicated Unit Count',\n",
       "       'Re-infested  Dwelling Unit Count', 'Filing Date',\n",
       "       'Filing Period Start Date', 'Filling Period End Date', 'Latitude',\n",
       "       'Longitude', 'Community Board', 'Council District', '2010 Census Tract',\n",
       "       'BIN', 'BBL', 'NTA'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pd.read_csv(\"data/Bedbug_Reporting_20231203.csv\")\n",
    "a.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from typing import List, Set\n",
    "\n",
    "def filter_bedbug(df: pd.DataFrame, column_needed: List[str], nyc_zip: Set[str]) -> gpd.GeoDataFrame:\n",
    "    # Ensure 'Postcode' and 'Filing Date' are in the needed columns\n",
    "    if 'Postcode' not in column_needed or 'Filing Date' not in column_needed:\n",
    "        raise ValueError(\"Required columns 'Postcode' and 'Filing Date' are missing.\")\n",
    "\n",
    "    # Selecting the required columns and drop rows with NaN values\n",
    "    filtered = df[column_needed].dropna()\n",
    "\n",
    "    # Further filter the DataFrame to only include rows where 'Postcode' is in nyc_zip\n",
    "    filtered = filtered[filtered['Postcode'].isin(nyc_zip)]\n",
    "\n",
    "    # Converting 'Filing Date' to datetime\n",
    "    filtered['Filing Date'] = pd.to_datetime(filtered['Filing Date'])\n",
    "\n",
    "    # Define your date range\n",
    "    start_date = pd.to_datetime('01/01/2015')\n",
    "    end_date = pd.to_datetime('09/30/2023')\n",
    "\n",
    "    # Filter the DataFrame for dates within the range\n",
    "    filtered = filtered[(filtered['Filing Date'] >= start_date) & (filtered['Filing Date'] <= end_date)]\n",
    "\n",
    "    # Convert to GeoDataFrame (assuming Latitude and Longitude columns are present)\n",
    "    if 'Latitude' in filtered.columns and 'Longitude' in filtered.columns:\n",
    "        return gpd.GeoDataFrame(filtered, geometry=gpd.points_from_xy(filtered['Longitude'], filtered['Latitude']))\n",
    "    else:\n",
    "        raise ValueError(\"Latitude and Longitude columns are required for GeoDataFrame conversion.\")\n",
    "\n",
    "    # If no Latitude and Longitude, just return the filtered DataFrame\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-07T20:45:27.670043600Z",
     "start_time": "2023-12-07T20:40:11.395069Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdf\\AppData\\Local\\Temp\\ipykernel_20368\\2172569232.py:14: DtypeWarning: Columns (8,31,32,34,35,36,37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv('data/311_Service_Requests_from_2010_to_Present_20231129.csv', chunksize=chunk_size):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows inserted: 70209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdf\\AppData\\Local\\Temp\\ipykernel_20368\\2172569232.py:14: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv('data/311_Service_Requests_from_2010_to_Present_20231129.csv', chunksize=chunk_size):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows inserted: 124724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdf\\AppData\\Local\\Temp\\ipykernel_20368\\2172569232.py:14: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv('data/311_Service_Requests_from_2010_to_Present_20231129.csv', chunksize=chunk_size):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows inserted: 207601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdf\\AppData\\Local\\Temp\\ipykernel_20368\\2172569232.py:14: DtypeWarning: Columns (8,31,32,33,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv('data/311_Service_Requests_from_2010_to_Present_20231129.csv', chunksize=chunk_size):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows inserted: 291330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdf\\AppData\\Local\\Temp\\ipykernel_20368\\2172569232.py:14: DtypeWarning: Columns (8,31,32,33,36) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv('data/311_Service_Requests_from_2010_to_Present_20231129.csv', chunksize=chunk_size):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows inserted: 360381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdf\\AppData\\Local\\Temp\\ipykernel_20368\\2172569232.py:14: DtypeWarning: Columns (8,31,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv('data/311_Service_Requests_from_2010_to_Present_20231129.csv', chunksize=chunk_size):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows inserted: 430125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdf\\AppData\\Local\\Temp\\ipykernel_20368\\2172569232.py:14: DtypeWarning: Columns (8,31,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv('data/311_Service_Requests_from_2010_to_Present_20231129.csv', chunksize=chunk_size):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows inserted: 472771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdf\\AppData\\Local\\Temp\\ipykernel_20368\\2172569232.py:14: DtypeWarning: Columns (8,31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv('data/311_Service_Requests_from_2010_to_Present_20231129.csv', chunksize=chunk_size):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows inserted: 542441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdf\\AppData\\Local\\Temp\\ipykernel_20368\\2172569232.py:14: DtypeWarning: Columns (8,17,31,32,33,34,35,36,37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv('data/311_Service_Requests_from_2010_to_Present_20231129.csv', chunksize=chunk_size):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows inserted: 599646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdf\\AppData\\Local\\Temp\\ipykernel_20368\\2172569232.py:14: DtypeWarning: Columns (8,18,31,32,33,34,35,36,37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv('data/311_Service_Requests_from_2010_to_Present_20231129.csv', chunksize=chunk_size):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows inserted: 671552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdf\\AppData\\Local\\Temp\\ipykernel_20368\\2172569232.py:14: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv('data/311_Service_Requests_from_2010_to_Present_20231129.csv', chunksize=chunk_size):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows inserted: 729595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdf\\AppData\\Local\\Temp\\ipykernel_20368\\2172569232.py:14: DtypeWarning: Columns (8,31,32,33,34,35,36,37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv('data/311_Service_Requests_from_2010_to_Present_20231129.csv', chunksize=chunk_size):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows inserted: 787869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdf\\AppData\\Local\\Temp\\ipykernel_20368\\2172569232.py:14: DtypeWarning: Columns (8,31,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv('data/311_Service_Requests_from_2010_to_Present_20231129.csv', chunksize=chunk_size):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows inserted: 860060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdf\\AppData\\Local\\Temp\\ipykernel_20368\\2172569232.py:14: DtypeWarning: Columns (8,18,31,32,33,34,35,36,37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv('data/311_Service_Requests_from_2010_to_Present_20231129.csv', chunksize=chunk_size):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows inserted: 918000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdf\\AppData\\Local\\Temp\\ipykernel_20368\\2172569232.py:14: DtypeWarning: Columns (8,31,32,35,36) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv('data/311_Service_Requests_from_2010_to_Present_20231129.csv', chunksize=chunk_size):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows inserted: 975690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdf\\AppData\\Local\\Temp\\ipykernel_20368\\2172569232.py:14: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv('data/311_Service_Requests_from_2010_to_Present_20231129.csv', chunksize=chunk_size):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows inserted: 1061519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdf\\AppData\\Local\\Temp\\ipykernel_20368\\2172569232.py:14: DtypeWarning: Columns (8,31,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv('data/311_Service_Requests_from_2010_to_Present_20231129.csv', chunksize=chunk_size):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows inserted: 1132578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdf\\AppData\\Local\\Temp\\ipykernel_20368\\2172569232.py:14: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv('data/311_Service_Requests_from_2010_to_Present_20231129.csv', chunksize=chunk_size):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows inserted: 1188341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdf\\AppData\\Local\\Temp\\ipykernel_20368\\2172569232.py:14: DtypeWarning: Columns (8,18,31,32,33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv('data/311_Service_Requests_from_2010_to_Present_20231129.csv', chunksize=chunk_size):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows inserted: 1244504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdf\\AppData\\Local\\Temp\\ipykernel_20368\\2172569232.py:14: DtypeWarning: Columns (8,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv('data/311_Service_Requests_from_2010_to_Present_20231129.csv', chunksize=chunk_size):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows inserted: 1314852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdf\\AppData\\Local\\Temp\\ipykernel_20368\\2172569232.py:14: DtypeWarning: Columns (8,31,32,33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv('data/311_Service_Requests_from_2010_to_Present_20231129.csv', chunksize=chunk_size):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows inserted: 1357111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdf\\AppData\\Local\\Temp\\ipykernel_20368\\2172569232.py:14: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv('data/311_Service_Requests_from_2010_to_Present_20231129.csv', chunksize=chunk_size):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows inserted: 1412126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdf\\AppData\\Local\\Temp\\ipykernel_20368\\2172569232.py:14: DtypeWarning: Columns (8,31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv('data/311_Service_Requests_from_2010_to_Present_20231129.csv', chunksize=chunk_size):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows inserted: 1466660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdf\\AppData\\Local\\Temp\\ipykernel_20368\\2172569232.py:14: DtypeWarning: Columns (8,31,32,33,34,35,36,37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv('data/311_Service_Requests_from_2010_to_Present_20231129.csv', chunksize=chunk_size):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows inserted: 1508614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdf\\AppData\\Local\\Temp\\ipykernel_20368\\2172569232.py:14: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv('data/311_Service_Requests_from_2010_to_Present_20231129.csv', chunksize=chunk_size):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows inserted: 1578444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdf\\AppData\\Local\\Temp\\ipykernel_20368\\2172569232.py:14: DtypeWarning: Columns (8,18,31,32,33,34,35,36,37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv('data/311_Service_Requests_from_2010_to_Present_20231129.csv', chunksize=chunk_size):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows inserted: 1636434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdf\\AppData\\Local\\Temp\\ipykernel_20368\\2172569232.py:14: DtypeWarning: Columns (8,31,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv('data/311_Service_Requests_from_2010_to_Present_20231129.csv', chunksize=chunk_size):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows inserted: 1665717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdf\\AppData\\Local\\Temp\\ipykernel_20368\\2172569232.py:14: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv('data/311_Service_Requests_from_2010_to_Present_20231129.csv', chunksize=chunk_size):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows inserted: 1694197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdf\\AppData\\Local\\Temp\\ipykernel_20368\\2172569232.py:14: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv('data/311_Service_Requests_from_2010_to_Present_20231129.csv', chunksize=chunk_size):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows inserted: 1751862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdf\\AppData\\Local\\Temp\\ipykernel_20368\\2172569232.py:14: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv('data/311_Service_Requests_from_2010_to_Present_20231129.csv', chunksize=chunk_size):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows inserted: 1811021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdf\\AppData\\Local\\Temp\\ipykernel_20368\\2172569232.py:14: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv('data/311_Service_Requests_from_2010_to_Present_20231129.csv', chunksize=chunk_size):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows inserted: 1885384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdf\\AppData\\Local\\Temp\\ipykernel_20368\\2172569232.py:14: DtypeWarning: Columns (8,34,35,36,37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv('data/311_Service_Requests_from_2010_to_Present_20231129.csv', chunksize=chunk_size):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows inserted: 1942994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdf\\AppData\\Local\\Temp\\ipykernel_20368\\2172569232.py:14: DtypeWarning: Columns (8,31,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv('data/311_Service_Requests_from_2010_to_Present_20231129.csv', chunksize=chunk_size):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows inserted: 2000158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdf\\AppData\\Local\\Temp\\ipykernel_20368\\2172569232.py:14: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv('data/311_Service_Requests_from_2010_to_Present_20231129.csv', chunksize=chunk_size):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows inserted: 2028916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdf\\AppData\\Local\\Temp\\ipykernel_20368\\2172569232.py:14: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv('data/311_Service_Requests_from_2010_to_Present_20231129.csv', chunksize=chunk_size):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows inserted: 2112690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdf\\AppData\\Local\\Temp\\ipykernel_20368\\2172569232.py:14: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv('data/311_Service_Requests_from_2010_to_Present_20231129.csv', chunksize=chunk_size):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows inserted: 2184753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdf\\AppData\\Local\\Temp\\ipykernel_20368\\2172569232.py:14: DtypeWarning: Columns (8,31,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv('data/311_Service_Requests_from_2010_to_Present_20231129.csv', chunksize=chunk_size):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows inserted: 2256611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdf\\AppData\\Local\\Temp\\ipykernel_20368\\2172569232.py:14: DtypeWarning: Columns (8,31,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv('data/311_Service_Requests_from_2010_to_Present_20231129.csv', chunksize=chunk_size):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows inserted: 2342127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdf\\AppData\\Local\\Temp\\ipykernel_20368\\2172569232.py:14: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv('data/311_Service_Requests_from_2010_to_Present_20231129.csv', chunksize=chunk_size):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows inserted: 2399204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdf\\AppData\\Local\\Temp\\ipykernel_20368\\2172569232.py:14: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv('data/311_Service_Requests_from_2010_to_Present_20231129.csv', chunksize=chunk_size):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows inserted: 2442730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdf\\AppData\\Local\\Temp\\ipykernel_20368\\2172569232.py:14: DtypeWarning: Columns (8,31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv('data/311_Service_Requests_from_2010_to_Present_20231129.csv', chunksize=chunk_size):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows inserted: 2500511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdf\\AppData\\Local\\Temp\\ipykernel_20368\\2172569232.py:14: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv('data/311_Service_Requests_from_2010_to_Present_20231129.csv', chunksize=chunk_size):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows inserted: 2586837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdf\\AppData\\Local\\Temp\\ipykernel_20368\\2172569232.py:14: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv('data/311_Service_Requests_from_2010_to_Present_20231129.csv', chunksize=chunk_size):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows inserted: 2658865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdf\\AppData\\Local\\Temp\\ipykernel_20368\\2172569232.py:14: DtypeWarning: Columns (8,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv('data/311_Service_Requests_from_2010_to_Present_20231129.csv', chunksize=chunk_size):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows inserted: 2747028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdf\\AppData\\Local\\Temp\\ipykernel_20368\\2172569232.py:14: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv('data/311_Service_Requests_from_2010_to_Present_20231129.csv', chunksize=chunk_size):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows inserted: 2790311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdf\\AppData\\Local\\Temp\\ipykernel_20368\\2172569232.py:14: DtypeWarning: Columns (8,31,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv('data/311_Service_Requests_from_2010_to_Present_20231129.csv', chunksize=chunk_size):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows inserted: 2863812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdf\\AppData\\Local\\Temp\\ipykernel_20368\\2172569232.py:14: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv('data/311_Service_Requests_from_2010_to_Present_20231129.csv', chunksize=chunk_size):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows inserted: 2908123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdf\\AppData\\Local\\Temp\\ipykernel_20368\\2172569232.py:14: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv('data/311_Service_Requests_from_2010_to_Present_20231129.csv', chunksize=chunk_size):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows inserted: 2923376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdf\\AppData\\Local\\Temp\\ipykernel_20368\\2172569232.py:14: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv('data/311_Service_Requests_from_2010_to_Present_20231129.csv', chunksize=chunk_size):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows inserted: 2952880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdf\\AppData\\Local\\Temp\\ipykernel_20368\\2172569232.py:14: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv('data/311_Service_Requests_from_2010_to_Present_20231129.csv', chunksize=chunk_size):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows inserted: 2996476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdf\\AppData\\Local\\Temp\\ipykernel_20368\\2172569232.py:14: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv('data/311_Service_Requests_from_2010_to_Present_20231129.csv', chunksize=chunk_size):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows inserted: 3071243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdf\\AppData\\Local\\Temp\\ipykernel_20368\\2172569232.py:14: DtypeWarning: Columns (8,31,32,34,35,36,37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv('data/311_Service_Requests_from_2010_to_Present_20231129.csv', chunksize=chunk_size):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows inserted: 3130919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdf\\AppData\\Local\\Temp\\ipykernel_20368\\2172569232.py:14: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv('data/311_Service_Requests_from_2010_to_Present_20231129.csv', chunksize=chunk_size):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows inserted: 3132033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdf\\AppData\\Local\\Temp\\ipykernel_20368\\2172569232.py:14: DtypeWarning: Columns (8,31,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv('data/311_Service_Requests_from_2010_to_Present_20231129.csv', chunksize=chunk_size):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows inserted: 3202322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdf\\AppData\\Local\\Temp\\ipykernel_20368\\2172569232.py:14: DtypeWarning: Columns (8,31,32,34,35,36,37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv('data/311_Service_Requests_from_2010_to_Present_20231129.csv', chunksize=chunk_size):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows inserted: 3260293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdf\\AppData\\Local\\Temp\\ipykernel_20368\\2172569232.py:14: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv('data/311_Service_Requests_from_2010_to_Present_20231129.csv', chunksize=chunk_size):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows inserted: 3303700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdf\\AppData\\Local\\Temp\\ipykernel_20368\\2172569232.py:14: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv('data/311_Service_Requests_from_2010_to_Present_20231129.csv', chunksize=chunk_size):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows inserted: 3361088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdf\\AppData\\Local\\Temp\\ipykernel_20368\\2172569232.py:14: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv('data/311_Service_Requests_from_2010_to_Present_20231129.csv', chunksize=chunk_size):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows inserted: 3449332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdf\\AppData\\Local\\Temp\\ipykernel_20368\\2172569232.py:14: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv('data/311_Service_Requests_from_2010_to_Present_20231129.csv', chunksize=chunk_size):\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Iterate through chunks of the CSV file and insert into the database\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/311_Service_Requests_from_2010_to_Present_20231129.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, chunksize\u001b[38;5;241m=\u001b[39mchunk_size):\n\u001b[1;32m---> 15\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m \u001b[43mfilter_t311\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcolumns_needed\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnyc_zip\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnyc_zips\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     chunk\u001b[38;5;241m.\u001b[39mto_sql(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt311\u001b[39m\u001b[38;5;124m'\u001b[39m, engine, if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mappend\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     17\u001b[0m     total_rows_inserted \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(chunk)\n",
      "Cell \u001b[1;32mIn[28], line 8\u001b[0m, in \u001b[0;36mfilter_t311\u001b[1;34m(df, column_needed, nyc_zip)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Further filter the DataFrame to only include rows where 'Incident Zip' is in nyc_zip\u001b[39;00m\n\u001b[0;32m      7\u001b[0m filtered \u001b[38;5;241m=\u001b[39m filtered[filtered[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIncident Zip\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin(nyc_zip)]\n\u001b[1;32m----> 8\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCreated Date\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCreated Date\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Define your date range\u001b[39;00m\n\u001b[0;32m     11\u001b[0m start_date \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2015-01-01\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1068\u001b[0m, in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m   1066\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mmap(cache_array)\n\u001b[0;32m   1067\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1068\u001b[0m         values \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1069\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39m_constructor(values, index\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mindex, name\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m   1070\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, (ABCDataFrame, abc\u001b[38;5;241m.\u001b[39mMutableMapping)):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:438\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[1;34m(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m infer_datetime_format\n\u001b[0;32m    437\u001b[0m utc \u001b[38;5;241m=\u001b[39m tz \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutc\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 438\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m \u001b[43mobjects_to_datetime64ns\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    439\u001b[0m \u001b[43m    \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    440\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdayfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdayfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    441\u001b[0m \u001b[43m    \u001b[49m\u001b[43myearfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myearfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    442\u001b[0m \u001b[43m    \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    444\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequire_iso8601\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequire_iso8601\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_object\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    446\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[0;32m    450\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n\u001b[0;32m    451\u001b[0m     dta \u001b[38;5;241m=\u001b[39m DatetimeArray(result, dtype\u001b[38;5;241m=\u001b[39mtz_to_dtype(tz_parsed))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:2177\u001b[0m, in \u001b[0;36mobjects_to_datetime64ns\u001b[1;34m(data, dayfirst, yearfirst, utc, errors, require_iso8601, allow_object, allow_mixed)\u001b[0m\n\u001b[0;32m   2175\u001b[0m order: Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m flags\u001b[38;5;241m.\u001b[39mf_contiguous \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2176\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2177\u001b[0m     result, tz_parsed \u001b[38;5;241m=\u001b[39m \u001b[43mtslib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray_to_datetime\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mK\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2179\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdayfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdayfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2182\u001b[0m \u001b[43m        \u001b[49m\u001b[43myearfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myearfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequire_iso8601\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequire_iso8601\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_mixed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_mixed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2185\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2186\u001b[0m     result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mreshape(data\u001b[38;5;241m.\u001b[39mshape, order\u001b[38;5;241m=\u001b[39morder)\n\u001b[0;32m   2187\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOverflowError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   2188\u001b[0m     \u001b[38;5;66;03m# Exception is raised when a part of date is greater than 32 bit signed int\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\tslib.pyx:427\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\tslib.pyx:605\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\tslibs\\parsing.pyx:318\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.parsing.parse_datetime_string\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\dateutil\\parser\\_parser.py:1368\u001b[0m, in \u001b[0;36mparse\u001b[1;34m(timestr, parserinfo, **kwargs)\u001b[0m\n\u001b[0;32m   1366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser(parserinfo)\u001b[38;5;241m.\u001b[39mparse(timestr, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1367\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1368\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DEFAULTPARSER\u001b[38;5;241m.\u001b[39mparse(timestr, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\dateutil\\parser\\_parser.py:649\u001b[0m, in \u001b[0;36mparser.parse\u001b[1;34m(self, timestr, default, ignoretz, tzinfos, **kwargs)\u001b[0m\n\u001b[0;32m    646\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ParserError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mString does not contain a date: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, timestr)\n\u001b[0;32m    648\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 649\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_naive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    650\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    651\u001b[0m     six\u001b[38;5;241m.\u001b[39mraise_from(ParserError(\u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, timestr), e)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\dateutil\\parser\\_parser.py:1221\u001b[0m, in \u001b[0;36mparser._build_naive\u001b[1;34m(self, res, default)\u001b[0m\n\u001b[0;32m   1218\u001b[0m repl \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   1219\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmonth\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mday\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhour\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1220\u001b[0m              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminute\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msecond\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmicrosecond\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1221\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1222\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1223\u001b[0m         repl[attr] \u001b[38;5;241m=\u001b[39m value\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "import geopandas as gpd\n",
    "# Define your database connection parameters\n",
    "db_connection_string = \"postgresql://postgres:1234@localhost:5432/e4501project\"\n",
    "engine = create_engine(db_connection_string)\n",
    "\n",
    "# Specify the chunk size\n",
    "chunk_size = 100000\n",
    "total_rows_inserted = 0\n",
    "\n",
    "# Iterate through chunks of the CSV file and insert into the database\n",
    "for chunk in pd.read_csv('data/311_Service_Requests_from_2010_to_Present_20231129.csv', chunksize=chunk_size):\n",
    "    chunk = filter_t311(chunk,columns_needed,nyc_zip=nyc_zips)\n",
    "    chunk.to_postgis('t311', engine, if_exists='append', index=False)\n",
    "    total_rows_inserted += len(chunk)\n",
    "    print(f\"Total rows inserted: {total_rows_inserted}\")\n",
    "#\n",
    "for chunk in pd.read_csv('data/2015StreetTreesCensus_TREES.csv', chunksize=chunk_size):\n",
    "    columns_needed = ['created_at','Latitude','longitude','tree_id','zipcode', 'health', 'spc_common']\n",
    "    chunk = filter_stc(chunk, columns_needed, nyc_zip=nyc_zips)\n",
    "    chunk.to_postgis('stc', engine, if_exists='append', index=False)\n",
    "    total_rows_inserted += len(chunk)\n",
    "    print(f\"Total rows inserted: {total_rows_inserted}\")\n",
    "\n",
    "\n",
    "for chunk in pd.read_csv('data/zillow_rent_data.csv', chunksize=chunk_size):\n",
    "    chunk = filter_zillow(chunk,nyc_zip=nyc_zips)\n",
    "    chunk.to_postgis('zillow', engine, if_exists='append', index=False)\n",
    "    total_rows_inserted += len(chunk)\n",
    "    print(f\"Total rows inserted: {total_rows_inserted}\")\n",
    "#\n",
    "# for chunk in pd.read_csv('data/Bedbug_Reporting_20231203.csv', chunksize=chunk_size):\n",
    "#     chunk.to_sql('Bedbug', engine, if_exists='append', index=False)\n",
    "#     total_rows_inserted += len(chunk)\n",
    "#     print(f\"Total rows inserted: {total_rows_inserted}\")\n",
    "#\n",
    "# gdf = gpd.read_file('data/nyc_zipcodes/nyc_zipcodes.shp')\n",
    "# gdf.to_postgis('nyc_shape', engine, if_exists='replace', index=False)\n",
    "# engine.dispose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Define your database connection parameters\n",
    "db_connection_string = \"postgresql://postgres:1234@localhost:5432/e4501project\"\n",
    "engine = create_engine(db_connection_string)\n",
    "\n",
    "# Specify the chunk size\n",
    "chunk_size = 100000\n",
    "\n",
    "# Initialize lists to hold processed chunks\n",
    "t311_chunks = []\n",
    "stc_chunks = []\n",
    "zillow_chunks = []\n",
    "bedbug_chunks = []\n",
    "\n",
    "# Process and store chunks for '311_Service_Requests'\n",
    "for chunk in pd.read_csv('data/311_Service_Requests_from_2010_to_Present_20231129.csv', chunksize=chunk_size):\n",
    "    columns_needed = ['Unique Key', 'Created Date', 'Complaint Type', 'Incident Zip', 'Latitude', 'Longitude', 'Location']\n",
    "    processed_chunk = filter_t311(chunk, columns_needed, nyc_zip=nyc_zips)\n",
    "    t311_chunks.append(processed_chunk)\n",
    "df_t311 = pd.concat(t311_chunks)\n",
    "# Process and store chunks for 'StreetTreesCensus_TREES'\n",
    "for chunk in pd.read_csv('data/2015StreetTreesCensus_TREES.csv', chunksize=chunk_size):\n",
    "    columns_needed = ['created_at', 'Latitude', 'longitude', 'tree_id', 'zipcode', 'health', 'spc_common']\n",
    "    processed_chunk = filter_stc(chunk, columns_needed, nyc_zip=nyc_zips)\n",
    "    stc_chunks.append(processed_chunk)\n",
    "df_stc = pd.concat(stc_chunks)\n",
    "# Process and store chunks for 'zillow_rent_data'\n",
    "for chunk in pd.read_csv('data/zillow_rent_data.csv', chunksize=chunk_size):\n",
    "    processed_chunk = filter_zillow(chunk, nyc_zip=nyc_zips)\n",
    "    zillow_chunks.append(processed_chunk)\n",
    "df_zillow = pd.concat(zillow_chunks)\n",
    "# Process and store chunks for 'Bedbug_Reporting'\n",
    "for chunk in pd.read_csv('data/Bedbug_Reporting_20231203.csv', chunksize=chunk_size):\n",
    "    columns_needed = ['Building ID', 'Postcode', 'Filing Date', 'Eradicated Unit Count', 'Re-infested  Dwelling Unit Count','Latitude','Longitude']\n",
    "    processed_chunk = filter_bedbug(chunk, columns_needed, nyc_zip=nyc_zips)\n",
    "    bedbug_chunks.append(processed_chunk)\n",
    "df_bedbug = pd.concat(bedbug_chunks)\n",
    "\n",
    "# Load shapefile and save to the database\n",
    "gdf = gpd.read_file('data/nyc_zipcodes/nyc_zipcodes.shp')\n",
    "gdf.to_postgis('nyc_shape', engine, if_exists='replace', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
