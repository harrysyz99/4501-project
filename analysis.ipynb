{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-10T17:06:34.631341Z",
     "start_time": "2023-12-10T17:06:31.645430Z"
    }
   },
   "outputs": [],
   "source": [
    "from shapely.geometry import Point\n",
    "import contextily as ctx\n",
    "from shapely.geometry import Point\n",
    "from typing import List, Union, Set\n",
    "import os\n",
    "import requests\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.sql import text\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from pandas import DataFrame\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-10T17:06:34.631687Z",
     "start_time": "2023-12-10T17:06:31.991001Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def read_shapefile(shapefile_path: str) -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Reads the shapefile into a GeoDataFrame.\n",
    "\n",
    "    Args:\n",
    "    - shapefile_path (str): Path to the shapefile.\n",
    "\n",
    "    Returns:\n",
    "    - gpd.GeoDataFrame: The GeoDataFrame read from the shapefile.\n",
    "    \"\"\"\n",
    "    return gpd.read_file(shapefile_path)\n",
    "\n",
    "def filter_columns(gdf: gpd.GeoDataFrame, columns: List[str]) -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Filters the GeoDataFrame to include only specified columns.\n",
    "\n",
    "    Args:\n",
    "    - gdf (gpd.GeoDataFrame): The original GeoDataFrame.\n",
    "    - columns (List[str]): A list of column names to retain.\n",
    "\n",
    "    Returns:\n",
    "    - gpd.GeoDataFrame: The GeoDataFrame with only the specified columns.\n",
    "    \"\"\"\n",
    "    return gdf[columns]\n",
    "\n",
    "def remove_duplicates(gdf: gpd.GeoDataFrame, subset: str) -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Removes duplicate rows based on a specified subset of columns.\n",
    "\n",
    "    Args:\n",
    "    - gdf (gpd.GeoDataFrame): The GeoDataFrame to process.\n",
    "    - subset (str): Column name to check for duplicates.\n",
    "\n",
    "    Returns:\n",
    "    - gpd.GeoDataFrame: The GeoDataFrame with duplicates removed.\n",
    "    \"\"\"\n",
    "    return gdf.drop_duplicates(subset=[subset])\n",
    "\n",
    "def filter_invalid_zipcodes(gdf: gpd.GeoDataFrame) -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Keeps only rows with valid 5-digit zipcodes.\n",
    "\n",
    "    Args:\n",
    "    - gdf (gpd.GeoDataFrame): The GeoDataFrame to process.\n",
    "\n",
    "    Returns:\n",
    "    - gpd.GeoDataFrame: The GeoDataFrame with only valid 5-digit zipcodes.\n",
    "    \"\"\"\n",
    "    gdf['zipcode'] = gdf['zipcode'].astype(str)\n",
    "    return gdf[gdf['zipcode'].str.isdigit() & (gdf['zipcode'].str.len() == 5)]\n",
    "\n",
    "def process_zipcode_shapefile(shapefile_path: str) -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Cleans and prepares a zipcode shapefile for analysis.\n",
    "\n",
    "    Args:\n",
    "    - shapefile_path (str): Path to the zipcode shapefile.\n",
    "\n",
    "    Returns:\n",
    "    - gpd.GeoDataFrame: GeoDataFrame with processed zipcode data.\n",
    "    \"\"\"\n",
    "    zipcode_gdf = read_shapefile(shapefile_path)\n",
    "    essential_columns = ['ZIPCODE', 'geometry']\n",
    "    zipcode_gdf = filter_columns(zipcode_gdf, essential_columns)\n",
    "    zipcode_gdf = remove_duplicates(zipcode_gdf, 'ZIPCODE')\n",
    "    zipcode_gdf.dropna(subset=essential_columns, inplace=True)\n",
    "    zipcode_gdf.rename(columns={'ZIPCODE': 'zipcode'}, inplace=True)\n",
    "    zipcode_gdf = filter_invalid_zipcodes(zipcode_gdf)\n",
    "    common_crs = \"EPSG:3857\"\n",
    "    zipcode_gdf.to_crs(common_crs, inplace=True)\n",
    "    zipcode_gdf.columns = map(str.lower, zipcode_gdf.columns)\n",
    "\n",
    "    return zipcode_gdf\n",
    "\n",
    "def lat_validation(latitude):\n",
    "    if not isinstance(latitude, (int, float)):\n",
    "        raise TypeError(\"The latitude should be a float or int type\")\n",
    "    return -90 <= latitude <= 90\n",
    "\n",
    "\n",
    "def long_validation(longitude: float) -> bool:\n",
    "    if not isinstance(longitude, (int, float)):\n",
    "        raise TypeError(\"The longitude should be a float or int type\")\n",
    "    return -180 <= longitude <= 180\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-10T17:06:34.632647Z",
     "start_time": "2023-12-10T17:06:31.993910Z"
    }
   },
   "outputs": [],
   "source": [
    "geodf_zip_data = process_zipcode_shapefile(\"data/nyc_zipcodes/nyc_zipcodes.shp\")\n",
    "nyc_zips = geodf_zip_data['zipcode'].tolist()\n",
    "nyc_zips = [float(element) for element in nyc_zips]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-10T17:06:34.632723Z",
     "start_time": "2023-12-10T17:06:32.215803Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "columns_needed = ['Unique Key', 'Created Date', 'Complaint Type', 'Incident Zip', 'Latitude', 'Longitude', 'Location']\n",
    "def filter_t311(df: pd.DataFrame, column_needed: List[str], nyc_zip: Union[Set[str], List[str]]) -> gpd.GeoDataFrame:\n",
    "    \n",
    "    df.columns = ['Unique Key', 'Created Date', 'Closed Date', 'Agency', 'Agency Name',\n",
    "       'Complaint Type', 'Descriptor', 'Location Type', 'Incident Zip',\n",
    "       'Incident Address', 'Street Name', 'Cross Street 1', 'Cross Street 2',\n",
    "       'Intersection Street 1', 'Intersection Street 2', 'Address Type',\n",
    "       'City', 'Landmark', 'Facility Type', 'Status', 'Due Date',\n",
    "       'Resolution Description', 'Resolution Action Updated Date',\n",
    "       'Community Board', 'BBL', 'Borough', 'X Coordinate (State Plane)',\n",
    "       'Y Coordinate (State Plane)', 'Open Data Channel Type',\n",
    "       'Park Facility Name', 'Park Borough', 'Vehicle Type',\n",
    "       'Taxi Company Borough', 'Taxi Pick Up Location', 'Bridge Highway Name',\n",
    "       'Bridge Highway Direction', 'Road Ramp', 'Bridge Highway Segment',\n",
    "       'Latitude', 'Longitude', 'Location']\n",
    "    # Filter the DataFrame to only include necessary columns and drop rows with NaN values\n",
    "    filtered = df[column_needed].dropna()\n",
    "\n",
    "    # Further filter the DataFrame to only include rows where 'Incident Zip' is in nyc_zip\n",
    "    filtered = filtered[filtered['Incident Zip'].isin(nyc_zip)]\n",
    "\n",
    "    # Converting 'Created Date' to datetime\n",
    "    filtered['Created Date'] = pd.to_datetime(filtered['Created Date'])\n",
    "\n",
    "    # Define your date range\n",
    "    start_date = pd.to_datetime('2015-01-01')\n",
    "    end_date = pd.to_datetime('2023-09-30')\n",
    "\n",
    "    # Filter the DataFrame for dates within the range\n",
    "    filtered = filtered[(filtered['Created Date'] >= start_date) & (filtered['Created Date'] <= end_date)]\n",
    "\n",
    "    # Apply latitude and longitude validation\n",
    "    filtered = filtered[filtered['Latitude'].apply(lat_validation) & filtered['Longitude'].apply(long_validation)]\n",
    "\n",
    "    # Convert to GeoDataFrame\n",
    "    filtered = gpd.GeoDataFrame(filtered, geometry=gpd.points_from_xy(filtered['Longitude'], filtered['Latitude']))\n",
    "    filtered.set_crs(\"EPSG:4326\", inplace=True)\n",
    "    filtered.to_crs(\"EPSG:3857\", inplace=True)\n",
    "\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-10T17:06:34.632778Z",
     "start_time": "2023-12-10T17:06:32.221565Z"
    }
   },
   "outputs": [],
   "source": [
    "## cehck\n",
    "def filter_stc(df: pd.DataFrame, column_needed: List[str], nyc_zip: Set[str]) -> gpd.GeoDataFrame:\n",
    "    \n",
    "    df.columns =['created_at', 'tree_id', 'block_id', 'the_geom', 'tree_dbh',\n",
    "       'stump_diam', 'curb_loc', 'status', 'health', 'spc_latin', 'spc_common',\n",
    "       'steward', 'guards', 'sidewalk', 'user_type', 'problems', 'root_stone',\n",
    "       'root_grate', 'root_other', 'trnk_wire', 'trnk_light', 'trnk_other',\n",
    "       'brnch_ligh', 'brnch_shoe', 'brnch_othe', 'address', 'zipcode',\n",
    "       'zip_city', 'cb_num', 'borocode', 'boroname', 'cncldist', 'st_assem',\n",
    "       'st_senate', 'nta', 'nta_name', 'boro_ct', 'state', 'Latitude',\n",
    "       'longitude', 'x_sp', 'y_sp']\n",
    "    # Filter the DataFrame to only include necessary columns and drop rows with NaN values\n",
    "    filtered = df[columns_needed].dropna()\n",
    "\n",
    "    # Further filter the DataFrame to only include rows where 'zipcode' is in nyc_zip\n",
    "    filtered = filtered[filtered['zipcode'].isin(nyc_zip)]\n",
    "\n",
    "    # Converting 'created_at' to datetime\n",
    "    filtered['created_at'] = pd.to_datetime(filtered['created_at'])\n",
    "\n",
    "    # Define your date range\n",
    "    start_date = pd.to_datetime('01/01/2015')\n",
    "    end_date = pd.to_datetime('09/30/2023')  # Corrected date\n",
    "\n",
    "    # Filter the DataFrame for dates within the range\n",
    "    filtered = filtered[(filtered['created_at'] >= start_date) & (filtered['created_at'] <= end_date)]\n",
    "\n",
    "    # Apply latitude and longitude validation\n",
    "    filtered = filtered[filtered['Latitude'].apply(lat_validation) & filtered['longitude'].apply(long_validation)]\n",
    "\n",
    "    # Convert to GeoDataFrame\n",
    "    filtered = gpd.GeoDataFrame(filtered, geometry=gpd.points_from_xy(filtered['longitude'], filtered['Latitude']))\n",
    "    filtered.set_crs(\"EPSG:4326\", inplace=True)\n",
    "    filtered.to_crs(\"EPSG:3857\", inplace=True)\n",
    "\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-10T17:06:34.632828Z",
     "start_time": "2023-12-10T17:06:32.224603Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def filter_zillow(df: pd.DataFrame, nyc_zip: list) -> pd.DataFrame:\n",
    "    # Selecting the required columns. Assuming the first column is 'RegionName' and the 9th to last are dates\n",
    "    useful_cols = df.columns[9:].to_list() + ['RegionName']+['RegionID']\n",
    "    filtered = df[useful_cols]\n",
    "\n",
    "    # Drop rows where 'RegionName' is NaN\n",
    "    filtered = filtered.dropna(subset=['RegionName'])\n",
    "    filtered = filtered.drop_duplicates()\n",
    "\n",
    "    # Filter rows where 'RegionName' is in the list of NYC zip codes\n",
    "    filtered = filtered[filtered['RegionName'].isin(nyc_zip)]\n",
    "    \n",
    "\n",
    "    # Melting the DataFrame\n",
    "    melted_df = filtered.melt(id_vars=['RegionID','RegionName'], value_vars=df.columns[9:], var_name='date', value_name='rent')\n",
    "    melted_df = melted_df.reset_index()\n",
    "    return melted_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-10T17:06:34.661638Z",
     "start_time": "2023-12-10T17:06:32.227422Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      RegionID  SizeRank  RegionName RegionType StateName State  \\\n0        91982         1       77494        zip        TX    TX   \n1        91940         3       77449        zip        TX    TX   \n2        91733         5       77084        zip        TX    TX   \n3        93144         6       79936        zip        TX    TX   \n4        62093         7       11385        zip        NY    NY   \n...        ...       ...         ...        ...       ...   ...   \n6717    418163     30158       89158        zip        NV    NV   \n6718     72017     30490       32461        zip        FL    FL   \n6719     58956     30490        2876        zip        RI    RI   \n6720     91179     30490       76005        zip        TX    TX   \n6721     61618     30490       10004        zip        NY    NY   \n\n                   City                                   Metro  \\\n0                  Katy    Houston-The Woodlands-Sugar Land, TX   \n1                  Katy    Houston-The Woodlands-Sugar Land, TX   \n2               Houston    Houston-The Woodlands-Sugar Land, TX   \n3               El Paso                             El Paso, TX   \n4              New York   New York-Newark-Jersey City, NY-NJ-PA   \n...                 ...                                     ...   \n6717          Las Vegas        Las Vegas-Henderson-Paradise, NV   \n6718  Panama City Beach  Crestview-Fort Walton Beach-Destin, FL   \n6719   North Smithfield               Providence-Warwick, RI-MA   \n6720          Arlington         Dallas-Fort Worth-Arlington, TX   \n6721           New York   New York-Newark-Jersey City, NY-NJ-PA   \n\n             CountyName   2015-01-31  ...   2022-12-31   2023-01-31  \\\n0      Fort Bend County  1606.206406  ...  1994.653463  2027.438438   \n1         Harris County  1257.814660  ...  1749.697900  1738.217986   \n2         Harris County          NaN  ...  1701.217520  1706.900064   \n3        El Paso County          NaN  ...  1419.480272  1458.063897   \n4         Queens County          NaN  ...  2935.808220  2895.699421   \n...                 ...          ...  ...          ...          ...   \n6717       Clark County          NaN  ...  3281.330738  3509.210744   \n6718      Walton County          NaN  ...          NaN          NaN   \n6719  Providence County          NaN  ...          NaN          NaN   \n6720     Tarrant County          NaN  ...  2148.224601  2169.143026   \n6721    New York County          NaN  ...  4006.972903  4000.923287   \n\n       2023-02-28   2023-03-31   2023-04-30   2023-05-31   2023-06-30  \\\n0     2042.237444  2049.325559  2016.531345  2023.438976  2031.558202   \n1     1747.305840  1758.407295  1758.891075  1762.980879  1771.751591   \n2     1706.067787  1723.722320  1735.484670  1752.132904  1756.990323   \n3     1471.726681  1466.734658  1456.175660  1462.478506  1466.267391   \n4     2873.209025  2881.906361  2913.546218  2963.964134  3005.735342   \n...           ...          ...          ...          ...          ...   \n6717  3407.499896  3438.041504  3436.371804  3524.703410  3426.708975   \n6718          NaN          NaN          NaN          NaN  2583.675563   \n6719          NaN          NaN          NaN          NaN          NaN   \n6720  2179.393248  2226.624684  2369.532530  2374.713926  2414.638428   \n6721  4002.584212  4085.513015  4224.569373  4240.040733  4286.776061   \n\n       2023-07-31   2023-08-31   2023-09-30  \n0     2046.144009  2053.486247  2055.771355  \n1     1779.338402  1795.384582  1799.631140  \n2     1754.429516  1757.602011  1755.031490  \n3     1490.237063  1488.180414  1494.366097  \n4     3034.413822  3064.476503  3079.585783  \n...           ...          ...          ...  \n6717  3412.249969  3310.302151  3448.166667  \n6718  2590.977335  2639.938102  2702.500000  \n6719          NaN          NaN  2250.000000  \n6720  2389.749852  2383.185013  2313.944444  \n6721  4270.158740  4353.055657  4355.328283  \n\n[6722 rows x 114 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RegionID</th>\n      <th>SizeRank</th>\n      <th>RegionName</th>\n      <th>RegionType</th>\n      <th>StateName</th>\n      <th>State</th>\n      <th>City</th>\n      <th>Metro</th>\n      <th>CountyName</th>\n      <th>2015-01-31</th>\n      <th>...</th>\n      <th>2022-12-31</th>\n      <th>2023-01-31</th>\n      <th>2023-02-28</th>\n      <th>2023-03-31</th>\n      <th>2023-04-30</th>\n      <th>2023-05-31</th>\n      <th>2023-06-30</th>\n      <th>2023-07-31</th>\n      <th>2023-08-31</th>\n      <th>2023-09-30</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>91982</td>\n      <td>1</td>\n      <td>77494</td>\n      <td>zip</td>\n      <td>TX</td>\n      <td>TX</td>\n      <td>Katy</td>\n      <td>Houston-The Woodlands-Sugar Land, TX</td>\n      <td>Fort Bend County</td>\n      <td>1606.206406</td>\n      <td>...</td>\n      <td>1994.653463</td>\n      <td>2027.438438</td>\n      <td>2042.237444</td>\n      <td>2049.325559</td>\n      <td>2016.531345</td>\n      <td>2023.438976</td>\n      <td>2031.558202</td>\n      <td>2046.144009</td>\n      <td>2053.486247</td>\n      <td>2055.771355</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>91940</td>\n      <td>3</td>\n      <td>77449</td>\n      <td>zip</td>\n      <td>TX</td>\n      <td>TX</td>\n      <td>Katy</td>\n      <td>Houston-The Woodlands-Sugar Land, TX</td>\n      <td>Harris County</td>\n      <td>1257.814660</td>\n      <td>...</td>\n      <td>1749.697900</td>\n      <td>1738.217986</td>\n      <td>1747.305840</td>\n      <td>1758.407295</td>\n      <td>1758.891075</td>\n      <td>1762.980879</td>\n      <td>1771.751591</td>\n      <td>1779.338402</td>\n      <td>1795.384582</td>\n      <td>1799.631140</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>91733</td>\n      <td>5</td>\n      <td>77084</td>\n      <td>zip</td>\n      <td>TX</td>\n      <td>TX</td>\n      <td>Houston</td>\n      <td>Houston-The Woodlands-Sugar Land, TX</td>\n      <td>Harris County</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1701.217520</td>\n      <td>1706.900064</td>\n      <td>1706.067787</td>\n      <td>1723.722320</td>\n      <td>1735.484670</td>\n      <td>1752.132904</td>\n      <td>1756.990323</td>\n      <td>1754.429516</td>\n      <td>1757.602011</td>\n      <td>1755.031490</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>93144</td>\n      <td>6</td>\n      <td>79936</td>\n      <td>zip</td>\n      <td>TX</td>\n      <td>TX</td>\n      <td>El Paso</td>\n      <td>El Paso, TX</td>\n      <td>El Paso County</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1419.480272</td>\n      <td>1458.063897</td>\n      <td>1471.726681</td>\n      <td>1466.734658</td>\n      <td>1456.175660</td>\n      <td>1462.478506</td>\n      <td>1466.267391</td>\n      <td>1490.237063</td>\n      <td>1488.180414</td>\n      <td>1494.366097</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>62093</td>\n      <td>7</td>\n      <td>11385</td>\n      <td>zip</td>\n      <td>NY</td>\n      <td>NY</td>\n      <td>New York</td>\n      <td>New York-Newark-Jersey City, NY-NJ-PA</td>\n      <td>Queens County</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>2935.808220</td>\n      <td>2895.699421</td>\n      <td>2873.209025</td>\n      <td>2881.906361</td>\n      <td>2913.546218</td>\n      <td>2963.964134</td>\n      <td>3005.735342</td>\n      <td>3034.413822</td>\n      <td>3064.476503</td>\n      <td>3079.585783</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6717</th>\n      <td>418163</td>\n      <td>30158</td>\n      <td>89158</td>\n      <td>zip</td>\n      <td>NV</td>\n      <td>NV</td>\n      <td>Las Vegas</td>\n      <td>Las Vegas-Henderson-Paradise, NV</td>\n      <td>Clark County</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>3281.330738</td>\n      <td>3509.210744</td>\n      <td>3407.499896</td>\n      <td>3438.041504</td>\n      <td>3436.371804</td>\n      <td>3524.703410</td>\n      <td>3426.708975</td>\n      <td>3412.249969</td>\n      <td>3310.302151</td>\n      <td>3448.166667</td>\n    </tr>\n    <tr>\n      <th>6718</th>\n      <td>72017</td>\n      <td>30490</td>\n      <td>32461</td>\n      <td>zip</td>\n      <td>FL</td>\n      <td>FL</td>\n      <td>Panama City Beach</td>\n      <td>Crestview-Fort Walton Beach-Destin, FL</td>\n      <td>Walton County</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2583.675563</td>\n      <td>2590.977335</td>\n      <td>2639.938102</td>\n      <td>2702.500000</td>\n    </tr>\n    <tr>\n      <th>6719</th>\n      <td>58956</td>\n      <td>30490</td>\n      <td>2876</td>\n      <td>zip</td>\n      <td>RI</td>\n      <td>RI</td>\n      <td>North Smithfield</td>\n      <td>Providence-Warwick, RI-MA</td>\n      <td>Providence County</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2250.000000</td>\n    </tr>\n    <tr>\n      <th>6720</th>\n      <td>91179</td>\n      <td>30490</td>\n      <td>76005</td>\n      <td>zip</td>\n      <td>TX</td>\n      <td>TX</td>\n      <td>Arlington</td>\n      <td>Dallas-Fort Worth-Arlington, TX</td>\n      <td>Tarrant County</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>2148.224601</td>\n      <td>2169.143026</td>\n      <td>2179.393248</td>\n      <td>2226.624684</td>\n      <td>2369.532530</td>\n      <td>2374.713926</td>\n      <td>2414.638428</td>\n      <td>2389.749852</td>\n      <td>2383.185013</td>\n      <td>2313.944444</td>\n    </tr>\n    <tr>\n      <th>6721</th>\n      <td>61618</td>\n      <td>30490</td>\n      <td>10004</td>\n      <td>zip</td>\n      <td>NY</td>\n      <td>NY</td>\n      <td>New York</td>\n      <td>New York-Newark-Jersey City, NY-NJ-PA</td>\n      <td>New York County</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>4006.972903</td>\n      <td>4000.923287</td>\n      <td>4002.584212</td>\n      <td>4085.513015</td>\n      <td>4224.569373</td>\n      <td>4240.040733</td>\n      <td>4286.776061</td>\n      <td>4270.158740</td>\n      <td>4353.055657</td>\n      <td>4355.328283</td>\n    </tr>\n  </tbody>\n</table>\n<p>6722 rows × 114 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pd.read_csv(\"data/zillow_rent_data.csv\")\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-10T17:06:34.662061Z",
     "start_time": "2023-12-10T17:06:32.295011Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "       index  RegionID  RegionName        date         rent\n0          0     62093       11385  2015-01-31          NaN\n1          1     62019       11208  2015-01-31          NaN\n2          2     62046       11236  2015-01-31          NaN\n3          3     61807       10467  2015-01-31          NaN\n4          4     62085       11373  2015-01-31          NaN\n...      ...       ...         ...         ...          ...\n15325  15325     61773       10282  2023-09-30  7347.458333\n15326  15326     62010       11109  2023-09-30  4529.358974\n15327  15327     61620       10006  2023-09-30  4060.096154\n15328  15328     61723       10162  2023-09-30  5011.666667\n15329  15329     61618       10004  2023-09-30  4355.328283\n\n[15330 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>RegionID</th>\n      <th>RegionName</th>\n      <th>date</th>\n      <th>rent</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>62093</td>\n      <td>11385</td>\n      <td>2015-01-31</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>62019</td>\n      <td>11208</td>\n      <td>2015-01-31</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>62046</td>\n      <td>11236</td>\n      <td>2015-01-31</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>61807</td>\n      <td>10467</td>\n      <td>2015-01-31</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>62085</td>\n      <td>11373</td>\n      <td>2015-01-31</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>15325</th>\n      <td>15325</td>\n      <td>61773</td>\n      <td>10282</td>\n      <td>2023-09-30</td>\n      <td>7347.458333</td>\n    </tr>\n    <tr>\n      <th>15326</th>\n      <td>15326</td>\n      <td>62010</td>\n      <td>11109</td>\n      <td>2023-09-30</td>\n      <td>4529.358974</td>\n    </tr>\n    <tr>\n      <th>15327</th>\n      <td>15327</td>\n      <td>61620</td>\n      <td>10006</td>\n      <td>2023-09-30</td>\n      <td>4060.096154</td>\n    </tr>\n    <tr>\n      <th>15328</th>\n      <td>15328</td>\n      <td>61723</td>\n      <td>10162</td>\n      <td>2023-09-30</td>\n      <td>5011.666667</td>\n    </tr>\n    <tr>\n      <th>15329</th>\n      <td>15329</td>\n      <td>61618</td>\n      <td>10004</td>\n      <td>2023-09-30</td>\n      <td>4355.328283</td>\n    </tr>\n  </tbody>\n</table>\n<p>15330 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_zillow(a,nyc_zips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-10T17:45:57.738223Z",
     "start_time": "2023-12-10T17:45:57.708015Z"
    }
   },
   "outputs": [],
   "source": [
    "def filter_bedbug(df: pd.DataFrame, column_needed: List[str], nyc_zip: Set[str]) -> gpd.GeoDataFrame:\n",
    "    df.columns = ['Building ID', 'Registration ID', 'Borough', 'House Number',\n",
    "       'Street Name', 'Postcode', '# of Dwelling Units',\n",
    "       'Infested Dwelling Unit Count', 'Eradicated Unit Count',\n",
    "       'Re-infested  Dwelling Unit Count', 'Filing Date',\n",
    "       'Filing Period Start Date', 'Filling Period End Date', 'Latitude',\n",
    "       'Longitude', 'Community Board', 'Council District', '2010 Census Tract',\n",
    "       'BIN', 'BBL', 'NTA']\n",
    "    # Ensure 'Postcode' and 'Filing Date' are in the needed columns\n",
    "    if 'Postcode' not in column_needed or 'Filing Date' not in column_needed:\n",
    "        raise ValueError(\"Required columns 'Postcode' and 'Filing Date' are missing.\")\n",
    "\n",
    "    # Selecting the required columns and drop rows with NaN values\n",
    "    filtered = df[column_needed].dropna()\n",
    "    filtered['Postcode']=filtered['Postcode'].astype(\"int\")\n",
    "    # Further filter the DataFrame to only include rows where 'Postcode' is in nyc_zip\n",
    "    filtered = filtered[filtered['Postcode'].isin(nyc_zip)]\n",
    "\n",
    "    # Converting 'Filing Date' to datetime\n",
    "    filtered['Filing Date'] = pd.to_datetime(filtered['Filing Date'])\n",
    "\n",
    "    # Define your date range\n",
    "    start_date = pd.to_datetime('01/01/2015')\n",
    "    end_date = pd.to_datetime('09/30/2023')\n",
    "\n",
    "    # Filter the DataFrame for dates within the range\n",
    "    filtered = filtered[(filtered['Filing Date'] >= start_date) & (filtered['Filing Date'] <= end_date)]\n",
    "    filtered = filtered.reset_index()\n",
    "    # Convert to GeoDataFrame (assuming Latitude and Longitude columns are present)\n",
    "    if 'Latitude' in filtered.columns and 'Longitude' in filtered.columns:\n",
    "        gdf = gpd.GeoDataFrame(filtered, geometry=gpd.points_from_xy(filtered['Longitude'], filtered['Latitude']))\n",
    "\n",
    "        # Set a CRS for the GeoDataFrame\n",
    "        # Replace 'EPSG:3857' with the correct EPSG code to match your PostGIS table\n",
    "        gdf.set_crs(epsg=3857, inplace=True)\n",
    "        return gdf\n",
    "    else:\n",
    "        raise ValueError(\"Latitude and Longitude columns are required for GeoDataFrame conversion.\")\n",
    "\n",
    "# Example usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "chunk_size = 100000\n",
    "\n",
    "# Initialize lists to hold processed chunks\n",
    "\n",
    "stc_chunks = []\n",
    "zillow_chunks = []\n",
    "bedbug_chunks = []"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T17:46:09.982033Z",
     "start_time": "2023-12-10T17:46:09.977010Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Process and store chunks for 'StreetTreesCensus_TREES'\n",
    "for chunk in pd.read_csv('data/2015StreetTreesCensus_TREES.csv', chunksize=chunk_size):\n",
    "    columns_needed = ['created_at', 'Latitude', 'longitude', 'tree_id', 'zipcode', 'health', 'spc_common']\n",
    "    processed_chunk = filter_stc(chunk, columns_needed, nyc_zip=nyc_zips)\n",
    "    stc_chunks.append(processed_chunk)\n",
    "geodf_tree_data = pd.concat(stc_chunks)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T17:06:36.595713Z",
     "start_time": "2023-12-10T17:06:32.330633Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Load shapefile and save to the database\n",
    "import geopandas as gpd\n",
    "\n",
    "# Load your shapefile\n",
    "geodf_zipcode_data = gpd.read_file('data/nyc_zipcodes/nyc_zipcodes.shp')\n",
    "\n",
    "# Selecting only the 'ZIPCODE' and 'geometry' columns\n",
    "geodf_zipcode_data = geodf_zipcode_data[['ZIPCODE', 'geometry']]\n",
    "\n",
    "# Set the initial CRS to EPSG:2263 if it's not already set\n",
    "geodf_zipcode_data.set_crs(epsg=2263, inplace=True)\n",
    "\n",
    "# Transform the CRS from EPSG:2263 to EPSG:3857\n",
    "geodf_zipcode_data = geodf_zipcode_data.to_crs(epsg=3857)\n",
    "geodf_zipcode_data = geodf_zipcode_data.drop_duplicates(subset=['ZIPCODE'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T17:06:36.777559Z",
     "start_time": "2023-12-10T17:06:36.595293Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Process and store chunks for 'zillow_rent_data'\n",
    "for chunk in pd.read_csv('data/zillow_rent_data.csv', chunksize=chunk_size):\n",
    "    processed_chunk = filter_zillow(chunk, nyc_zip=nyc_zips)\n",
    "    zillow_chunks.append(processed_chunk)\n",
    "df_zillow_data = pd.concat(zillow_chunks)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T17:06:36.846173Z",
     "start_time": "2023-12-10T17:06:36.760908Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "# Process and store chunks for 'Bedbug_Reporting'\n",
    "for chunk in pd.read_csv('data/Bedbug_Reporting_20231203.csv', chunksize=chunk_size):\n",
    "    columns_needed = ['Building ID', 'Postcode', 'Filing Date', 'Eradicated Unit Count', 'Re-infested  Dwelling Unit Count','Latitude','Longitude']\n",
    "    processed_chunk = filter_bedbug(chunk, columns_needed, nyc_zip=nyc_zips)\n",
    "    bedbug_chunks.append(processed_chunk)\n",
    "df_bedbug_data = pd.concat(bedbug_chunks)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T17:46:17.443292Z",
     "start_time": "2023-12-10T17:46:16.231988Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# Specify the chunk size\n",
    "t311_chunks = []\n",
    "\n",
    "# Process and store chunks for '311_Service_Requests'\n",
    "for chunk in pd.read_csv('data/311_Service_Requests_from_2010_to_Present_20231129.csv', chunksize=chunk_size):\n",
    "    columns_needed = ['Unique Key', 'Created Date', 'Complaint Type', 'Incident Zip', 'Latitude', 'Longitude', 'Location']\n",
    "    processed_chunk = filter_t311(chunk, columns_needed, nyc_zip=nyc_zips)\n",
    "    t311_chunks.append(processed_chunk)\n",
    "geodf_311_data = pd.concat(t311_chunks)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T17:24:30.103855Z",
     "start_time": "2023-12-10T17:11:27.154449Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-10T17:24:30.165030Z",
     "start_time": "2023-12-10T17:24:30.112320Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "Index: 248 entries, 0 to 262\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype   \n",
      "---  ------    --------------  -----   \n",
      " 0   ZIPCODE   248 non-null    object  \n",
      " 1   geometry  248 non-null    geometry\n",
      "dtypes: geometry(1), object(1)\n",
      "memory usage: 5.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# Show basic info about each dataframe\n",
    "geodf_zipcode_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-10T17:24:30.231169Z",
     "start_time": "2023-12-10T17:24:30.113590Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  ZIPCODE                                           geometry\n0   11436  POLYGON ((-8216029.470 4965682.769, -8216011.9...\n1   11213  POLYGON ((-8230673.455 4965216.008, -8230392.3...\n2   11212  POLYGON ((-8226837.796 4963911.170, -8226758.2...\n3   11225  POLYGON ((-8232963.912 4963884.338, -8232717.3...\n4   11218  POLYGON ((-8234534.400 4960940.544, -8234516.0...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ZIPCODE</th>\n      <th>geometry</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>11436</td>\n      <td>POLYGON ((-8216029.470 4965682.769, -8216011.9...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>11213</td>\n      <td>POLYGON ((-8230673.455 4965216.008, -8230392.3...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>11212</td>\n      <td>POLYGON ((-8226837.796 4963911.170, -8226758.2...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>11225</td>\n      <td>POLYGON ((-8232963.912 4963884.338, -8232717.3...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11218</td>\n      <td>POLYGON ((-8234534.400 4960940.544, -8234516.0...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show first 5 entries about each dataframe\n",
    "geodf_zipcode_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-10T17:24:30.231449Z",
     "start_time": "2023-12-10T17:24:30.138127Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "Index: 19436579 entries, 2796244 to 33897229\n",
      "Data columns (total 8 columns):\n",
      " #   Column          Dtype         \n",
      "---  ------          -----         \n",
      " 0   Unique Key      int64         \n",
      " 1   Created Date    datetime64[ns]\n",
      " 2   Complaint Type  object        \n",
      " 3   Incident Zip    object        \n",
      " 4   Latitude        float64       \n",
      " 5   Longitude       float64       \n",
      " 6   Location        object        \n",
      " 7   geometry        geometry      \n",
      "dtypes: datetime64[ns](1), float64(2), geometry(1), int64(1), object(3)\n",
      "memory usage: 1.3+ GB\n"
     ]
    }
   ],
   "source": [
    "geodf_311_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-10T17:24:30.231748Z",
     "start_time": "2023-12-10T17:24:30.146720Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "         Unique Key        Created Date                   Complaint Type  \\\n2796244    22333067 2020-04-15 14:17:16  Construction Safety Enforcement   \n6967776    27462375 2015-10-01 00:00:00   Unsanitary Animal Pvt Property   \n7064133    27684062 2015-10-01 00:00:00   Unsanitary Animal Pvt Property   \n7184490    27814302 2015-10-01 00:00:00   Unsanitary Animal Pvt Property   \n7314518    29672793 2015-01-06 07:17:31                 Street Condition   \n\n        Incident Zip   Latitude  Longitude  \\\n2796244      11205.0  40.697312 -73.964802   \n6967776      11414.0  40.660428 -73.841226   \n7064133      10301.0  40.633330 -74.105250   \n7184490      11417.0  40.684300 -73.837892   \n7314518      11235.0  40.593575 -73.932814   \n\n                                         Location  \\\n2796244   (40.69731208999635, -73.96480244651633)   \n6967776   (40.66042792940118, -73.84122633877455)   \n7064133   (40.63332969998893, -74.10525005425679)   \n7184490   (40.68430012358396, -73.83789200050686)   \n7314518  (40.593575191824996, -73.93281445608707)   \n\n                                 geometry  \n2796244  POINT (-8233724.145 4967797.263)  \n6967776  POINT (-8219967.716 4962383.151)  \n7064133  POINT (-8249358.701 4958407.393)  \n7184490  POINT (-8219596.539 4965886.935)  \n7314518  POINT (-8230163.258 4952577.668)  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unique Key</th>\n      <th>Created Date</th>\n      <th>Complaint Type</th>\n      <th>Incident Zip</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>Location</th>\n      <th>geometry</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2796244</th>\n      <td>22333067</td>\n      <td>2020-04-15 14:17:16</td>\n      <td>Construction Safety Enforcement</td>\n      <td>11205.0</td>\n      <td>40.697312</td>\n      <td>-73.964802</td>\n      <td>(40.69731208999635, -73.96480244651633)</td>\n      <td>POINT (-8233724.145 4967797.263)</td>\n    </tr>\n    <tr>\n      <th>6967776</th>\n      <td>27462375</td>\n      <td>2015-10-01 00:00:00</td>\n      <td>Unsanitary Animal Pvt Property</td>\n      <td>11414.0</td>\n      <td>40.660428</td>\n      <td>-73.841226</td>\n      <td>(40.66042792940118, -73.84122633877455)</td>\n      <td>POINT (-8219967.716 4962383.151)</td>\n    </tr>\n    <tr>\n      <th>7064133</th>\n      <td>27684062</td>\n      <td>2015-10-01 00:00:00</td>\n      <td>Unsanitary Animal Pvt Property</td>\n      <td>10301.0</td>\n      <td>40.633330</td>\n      <td>-74.105250</td>\n      <td>(40.63332969998893, -74.10525005425679)</td>\n      <td>POINT (-8249358.701 4958407.393)</td>\n    </tr>\n    <tr>\n      <th>7184490</th>\n      <td>27814302</td>\n      <td>2015-10-01 00:00:00</td>\n      <td>Unsanitary Animal Pvt Property</td>\n      <td>11417.0</td>\n      <td>40.684300</td>\n      <td>-73.837892</td>\n      <td>(40.68430012358396, -73.83789200050686)</td>\n      <td>POINT (-8219596.539 4965886.935)</td>\n    </tr>\n    <tr>\n      <th>7314518</th>\n      <td>29672793</td>\n      <td>2015-01-06 07:17:31</td>\n      <td>Street Condition</td>\n      <td>11235.0</td>\n      <td>40.593575</td>\n      <td>-73.932814</td>\n      <td>(40.593575191824996, -73.93281445608707)</td>\n      <td>POINT (-8230163.258 4952577.668)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geodf_311_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-10T17:24:30.255553Z",
     "start_time": "2023-12-10T17:24:30.150105Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "Index: 652167 entries, 0 to 683787\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count   Dtype         \n",
      "---  ------      --------------   -----         \n",
      " 0   created_at  652167 non-null  datetime64[ns]\n",
      " 1   Latitude    652167 non-null  float64       \n",
      " 2   longitude   652167 non-null  float64       \n",
      " 3   tree_id     652167 non-null  int64         \n",
      " 4   zipcode     652167 non-null  int64         \n",
      " 5   health      652167 non-null  object        \n",
      " 6   spc_common  652167 non-null  object        \n",
      " 7   geometry    652167 non-null  geometry      \n",
      "dtypes: datetime64[ns](1), float64(2), geometry(1), int64(2), object(2)\n",
      "memory usage: 44.8+ MB\n"
     ]
    }
   ],
   "source": [
    "geodf_tree_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-10T17:24:30.255987Z",
     "start_time": "2023-12-10T17:24:30.208926Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  created_at   Latitude  longitude  tree_id  zipcode health       spc_common  \\\n0 2015-08-27  40.723092 -73.844215   180683    11375   Fair        red maple   \n1 2015-09-03  40.794111 -73.818679   200540    11357   Fair          pin oak   \n2 2015-09-05  40.717581 -73.936608   204026    11211   Good      honeylocust   \n3 2015-09-05  40.713537 -73.934456   204337    11211   Good      honeylocust   \n4 2015-08-30  40.666778 -73.975979   189565    11215   Good  American linden   \n\n                           geometry  \n0  POINT (-8220300.436 4971583.163)  \n1  POINT (-8217457.809 4982020.303)  \n2  POINT (-8230585.520 4970773.712)  \n3  POINT (-8230346.012 4970179.889)  \n4  POINT (-8234968.356 4963315.009)  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>created_at</th>\n      <th>Latitude</th>\n      <th>longitude</th>\n      <th>tree_id</th>\n      <th>zipcode</th>\n      <th>health</th>\n      <th>spc_common</th>\n      <th>geometry</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2015-08-27</td>\n      <td>40.723092</td>\n      <td>-73.844215</td>\n      <td>180683</td>\n      <td>11375</td>\n      <td>Fair</td>\n      <td>red maple</td>\n      <td>POINT (-8220300.436 4971583.163)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2015-09-03</td>\n      <td>40.794111</td>\n      <td>-73.818679</td>\n      <td>200540</td>\n      <td>11357</td>\n      <td>Fair</td>\n      <td>pin oak</td>\n      <td>POINT (-8217457.809 4982020.303)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2015-09-05</td>\n      <td>40.717581</td>\n      <td>-73.936608</td>\n      <td>204026</td>\n      <td>11211</td>\n      <td>Good</td>\n      <td>honeylocust</td>\n      <td>POINT (-8230585.520 4970773.712)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2015-09-05</td>\n      <td>40.713537</td>\n      <td>-73.934456</td>\n      <td>204337</td>\n      <td>11211</td>\n      <td>Good</td>\n      <td>honeylocust</td>\n      <td>POINT (-8230346.012 4970179.889)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2015-08-30</td>\n      <td>40.666778</td>\n      <td>-73.975979</td>\n      <td>189565</td>\n      <td>11215</td>\n      <td>Good</td>\n      <td>American linden</td>\n      <td>POINT (-8234968.356 4963315.009)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geodf_tree_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-10T17:24:30.256121Z",
     "start_time": "2023-12-10T17:24:30.212052Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15330 entries, 0 to 15329\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   index       15330 non-null  int64  \n",
      " 1   RegionID    15330 non-null  int64  \n",
      " 2   RegionName  15330 non-null  int64  \n",
      " 3   date        15330 non-null  object \n",
      " 4   rent        9041 non-null   float64\n",
      "dtypes: float64(1), int64(3), object(1)\n",
      "memory usage: 599.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_zillow_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-10T17:24:30.286586Z",
     "start_time": "2023-12-10T17:24:30.218394Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   index  RegionID  RegionName        date  rent\n0      0     62093       11385  2015-01-31   NaN\n1      1     62019       11208  2015-01-31   NaN\n2      2     62046       11236  2015-01-31   NaN\n3      3     61807       10467  2015-01-31   NaN\n4      4     62085       11373  2015-01-31   NaN",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>RegionID</th>\n      <th>RegionName</th>\n      <th>date</th>\n      <th>rent</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>62093</td>\n      <td>11385</td>\n      <td>2015-01-31</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>62019</td>\n      <td>11208</td>\n      <td>2015-01-31</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>62046</td>\n      <td>11236</td>\n      <td>2015-01-31</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>61807</td>\n      <td>10467</td>\n      <td>2015-01-31</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>62085</td>\n      <td>11373</td>\n      <td>2015-01-31</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_zillow_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-10T17:46:23.965175Z",
     "start_time": "2023-12-10T17:46:23.922325Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "Index: 364683 entries, 0 to 68765\n",
      "Data columns (total 9 columns):\n",
      " #   Column                            Non-Null Count   Dtype         \n",
      "---  ------                            --------------   -----         \n",
      " 0   index                             364683 non-null  int64         \n",
      " 1   Building ID                       364683 non-null  int64         \n",
      " 2   Postcode                          364683 non-null  int64         \n",
      " 3   Filing Date                       364683 non-null  datetime64[ns]\n",
      " 4   Eradicated Unit Count             364683 non-null  float64       \n",
      " 5   Re-infested  Dwelling Unit Count  364683 non-null  float64       \n",
      " 6   Latitude                          364683 non-null  float64       \n",
      " 7   Longitude                         364683 non-null  float64       \n",
      " 8   geometry                          364683 non-null  geometry      \n",
      "dtypes: datetime64[ns](1), float64(4), geometry(1), int64(3)\n",
      "memory usage: 27.8 MB\n"
     ]
    }
   ],
   "source": [
    "df_bedbug_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T17:24:30.411566Z",
     "start_time": "2023-12-10T17:24:30.244312Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   index  Building ID  Postcode Filing Date  Eradicated Unit Count  \\\n0      0       344156   11222.0  2021-02-16                    0.0   \n1      1       170777   11204.0  2022-03-04                    0.0   \n2      2       358122   11216.0  2023-07-10                    0.0   \n3      3       705843   11385.0  2021-05-05                    0.0   \n4      4       877716   11212.0  2023-07-06                    0.0   \n\n   Re-infested  Dwelling Unit Count   Latitude  Longitude  \\\n0                               0.0  40.727680 -73.949030   \n1                               0.0  40.613333 -73.994291   \n2                               0.0  40.684545 -73.945667   \n3                               0.0  40.702903 -73.902286   \n4                               0.0  40.656147 -73.903403   \n\n                 geometry  \n0  POINT (-73.949 40.728)  \n1  POINT (-73.994 40.613)  \n2  POINT (-73.946 40.685)  \n3  POINT (-73.902 40.703)  \n4  POINT (-73.903 40.656)  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>Building ID</th>\n      <th>Postcode</th>\n      <th>Filing Date</th>\n      <th>Eradicated Unit Count</th>\n      <th>Re-infested  Dwelling Unit Count</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>geometry</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>344156</td>\n      <td>11222.0</td>\n      <td>2021-02-16</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>40.727680</td>\n      <td>-73.949030</td>\n      <td>POINT (-73.949 40.728)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>170777</td>\n      <td>11204.0</td>\n      <td>2022-03-04</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>40.613333</td>\n      <td>-73.994291</td>\n      <td>POINT (-73.994 40.613)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>358122</td>\n      <td>11216.0</td>\n      <td>2023-07-10</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>40.684545</td>\n      <td>-73.945667</td>\n      <td>POINT (-73.946 40.685)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>705843</td>\n      <td>11385.0</td>\n      <td>2021-05-05</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>40.702903</td>\n      <td>-73.902286</td>\n      <td>POINT (-73.902 40.703)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>877716</td>\n      <td>11212.0</td>\n      <td>2023-07-06</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>40.656147</td>\n      <td>-73.903403</td>\n      <td>POINT (-73.903 40.656)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bedbug_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Storing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-10T17:27:21.660496Z",
     "start_time": "2023-12-10T17:27:20.764203Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE EXTENSION\r\n"
     ]
    }
   ],
   "source": [
    "# this code is not be able to use \n",
    "!createdb e4501project\n",
    "!psql --dbname e4501project -c 'CREATE EXTENSION if NOT EXISTS postgis;'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Tables\n",
    "\n",
    "\n",
    "These are just a couple of options to creating your tables; you can use one or the other, a different method, or a combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-10T17:28:33.830169Z",
     "start_time": "2023-12-10T17:28:33.785436Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define your database connection parameters\n",
    "db_connection_string = \"postgresql://postgres:1234@localhost:5432/e4501project\"\n",
    "engine = create_engine(db_connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-10T17:28:35.101940Z",
     "start_time": "2023-12-10T17:28:35.074758Z"
    }
   },
   "outputs": [],
   "source": [
    "ZIPCODE_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS nyc_shape (\n",
    "  \"ZIPCODE\" int8 PRIMARY KEY,\n",
    "  \"geometry\" geometry(POLYGON, 3857)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "NYC_311_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS t311 (\n",
    "    \"Unique Key\" int8 PRIMARY KEY,\n",
    "    \"Created Date\" timestamp(6),\n",
    "    \"Complaint Type\" text COLLATE \"pg_catalog\".\"default\",\n",
    "    \"Incident Zip\" int8,\n",
    "    \"Latitude\" float8,\n",
    "    \"Longitude\" float8,\n",
    "    \"Location\" text COLLATE \"pg_catalog\".\"default\",\n",
    "    \"geometry\" geometry(POINT, 3857)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "NYC_TREE_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS stc (\n",
    "    \"created_at\" timestamp(6),\n",
    "    \"Latitude\" float8,\n",
    "    \"longitude\" float8,\n",
    "    \"tree_id\" int8 PRIMARY KEY,\n",
    "    \"zipcode\" int8,\n",
    "    \"status\" TEXT,\n",
    "    \"health\" text COLLATE \"pg_catalog\".\"default\",\n",
    "    \"spc_common\" text COLLATE \"pg_catalog\".\"default\",\n",
    "    \"geometry\" geometry(POINT, 3857)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "ZILLOW_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS zillow (\n",
    "  \"index\" int8 PRIMARY KEY,\n",
    "  \"RegionID\" int8,\n",
    "  \"RegionName\" int8,\n",
    "  \"date\" DATE,\n",
    "  \"rent\" float8\n",
    ")\n",
    ";\n",
    "\"\"\"\n",
    "\n",
    "BEDBUG_SCHEMA = '''\n",
    "CREATE TABLE IF NOT EXISTS Bedbug (\n",
    "  \"index\" int   PRIMARY KEY,\n",
    "  \"Building ID\" int8,\n",
    "  \"Postcode\" int8,\n",
    "  \"Filing Date\" timestamp(6),\n",
    "  \"Eradicated Unit Count\" float8,\n",
    "  \"Re-infested  Dwelling Unit Count\" float8,\n",
    "  \"Latitude\" float8,\n",
    "  \"Longitude\" float8,\n",
    "  \"geometry\" geometry(POINT,3857)\n",
    ");\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-10T17:28:36.243531Z",
     "start_time": "2023-12-10T17:28:36.221973Z"
    }
   },
   "outputs": [],
   "source": [
    "# create that required schema.sql file\n",
    "with open('schema.sql', \"w\") as f:\n",
    "    f.write(ZIPCODE_SCHEMA)\n",
    "    f.write(NYC_311_SCHEMA)\n",
    "    f.write(NYC_TREE_SCHEMA)\n",
    "    f.write(ZILLOW_SCHEMA)\n",
    "    f.write(BEDBUG_SCHEMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE\r\n",
      "CREATE TABLE\r\n",
      "CREATE TABLE\r\n",
      "CREATE TABLE\r\n",
      "CREATE TABLE\r\n"
     ]
    }
   ],
   "source": [
    "!psql --dbname e4501project -f schema.sql"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T17:42:11.619002Z",
     "start_time": "2023-12-10T17:42:11.397274Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-10T17:40:15.358309Z",
     "start_time": "2023-12-10T17:40:15.292983Z"
    }
   },
   "outputs": [
    {
     "ename": "ObjectNotExecutableError",
     "evalue": "Not an executable object: '\\nCREATE TABLE IF NOT EXISTS nyc_shape (\\n  \"ZIPCODE\" int8 PRIMARY KEY,\\n  \"geometry\" geometry(POLYGON, 3857)\\n);\\n\\nCREATE TABLE IF NOT EXISTS t311 (\\n    \"Unique Key\" int8 PRIMARY KEY,\\n    \"Created Date\" timestamp(6),\\n    \"Complaint Type\" text COLLATE \"pg_catalog\".\"default\",\\n    \"Incident Zip\" int8,\\n    \"Latitude\" float8,\\n    \"Longitude\" float8,\\n    \"Location\" text COLLATE \"pg_catalog\".\"default\",\\n    \"geometry\" geometry(POINT, 3857)\\n);\\n\\nCREATE TABLE IF NOT EXISTS stc (\\n    \"created_at\" timestamp(6),\\n    \"Latitude\" float8,\\n    \"longitude\" float8,\\n    \"tree_id\" int8 PRIMARY KEY,\\n    \"zipcode\" int8,\\n    \"status\" TEXT,\\n    \"health\" text COLLATE \"pg_catalog\".\"default\",\\n    \"spc_common\" text COLLATE \"pg_catalog\".\"default\",\\n    \"geometry\" geometry(POINT, 3857)\\n);\\n\\nCREATE TABLE IF NOT EXISTS zillow (\\n  \"index\" int8 PRIMARY KEY,\\n  \"RegionID\" int8,\\n  \"RegionName\" int8,\\n  \"date\" DATE,\\n  \"rent\" float8\\n)\\n;\\n\\nCREATE TABLE IF NOT EXISTS Bedbug (\\n  \"index\" int   PRIMARY KEY,\\n  \"Building ID\" int8,\\n  \"Postcode\" int8,\\n  \"Filing Date\" timestamp(6),\\n  \"Eradicated Unit Count\" float8,\\n  \"Re-infested  Dwelling Unit Count\" float8,\\n  \"Latitude\" float8,\\n  \"Longitude\" float8,\\n  \"geometry\" geometry(POINT,3857)\\n);\\n'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "File \u001B[0;32m~/mambaforge/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1408\u001B[0m, in \u001B[0;36mConnection.execute\u001B[0;34m(self, statement, parameters, execution_options)\u001B[0m\n\u001B[1;32m   1407\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1408\u001B[0m     meth \u001B[38;5;241m=\u001B[39m statement\u001B[38;5;241m.\u001B[39m_execute_on_connection\n\u001B[1;32m   1409\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'str' object has no attribute '_execute_on_connection'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mObjectNotExecutableError\u001B[0m                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[49], line 18\u001B[0m\n\u001B[1;32m     16\u001B[0m transaction\u001B[38;5;241m.\u001B[39mrollback()\n\u001B[1;32m     17\u001B[0m \u001B[38;5;66;03m# Optionally, re-raise the exception or handle it as needed\u001B[39;00m\n\u001B[0;32m---> 18\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m e\n",
      "Cell \u001B[0;32mIn[49], line 11\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m connection\u001B[38;5;241m.\u001B[39mbegin() \u001B[38;5;28;01mas\u001B[39;00m transaction:\n\u001B[1;32m     10\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 11\u001B[0m         connection\u001B[38;5;241m.\u001B[39mexecute(schema_sql)\n\u001B[1;32m     12\u001B[0m         \u001B[38;5;66;03m# Commit the transaction if all commands execute successfully\u001B[39;00m\n\u001B[1;32m     13\u001B[0m         transaction\u001B[38;5;241m.\u001B[39mcommit()\n",
      "File \u001B[0;32m~/mambaforge/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1410\u001B[0m, in \u001B[0;36mConnection.execute\u001B[0;34m(self, statement, parameters, execution_options)\u001B[0m\n\u001B[1;32m   1408\u001B[0m     meth \u001B[38;5;241m=\u001B[39m statement\u001B[38;5;241m.\u001B[39m_execute_on_connection\n\u001B[1;32m   1409\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m-> 1410\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m exc\u001B[38;5;241m.\u001B[39mObjectNotExecutableError(statement) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[1;32m   1411\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1412\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m meth(\n\u001B[1;32m   1413\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   1414\u001B[0m         distilled_parameters,\n\u001B[1;32m   1415\u001B[0m         execution_options \u001B[38;5;129;01mor\u001B[39;00m NO_OPTIONS,\n\u001B[1;32m   1416\u001B[0m     )\n",
      "\u001B[0;31mObjectNotExecutableError\u001B[0m: Not an executable object: '\\nCREATE TABLE IF NOT EXISTS nyc_shape (\\n  \"ZIPCODE\" int8 PRIMARY KEY,\\n  \"geometry\" geometry(POLYGON, 3857)\\n);\\n\\nCREATE TABLE IF NOT EXISTS t311 (\\n    \"Unique Key\" int8 PRIMARY KEY,\\n    \"Created Date\" timestamp(6),\\n    \"Complaint Type\" text COLLATE \"pg_catalog\".\"default\",\\n    \"Incident Zip\" int8,\\n    \"Latitude\" float8,\\n    \"Longitude\" float8,\\n    \"Location\" text COLLATE \"pg_catalog\".\"default\",\\n    \"geometry\" geometry(POINT, 3857)\\n);\\n\\nCREATE TABLE IF NOT EXISTS stc (\\n    \"created_at\" timestamp(6),\\n    \"Latitude\" float8,\\n    \"longitude\" float8,\\n    \"tree_id\" int8 PRIMARY KEY,\\n    \"zipcode\" int8,\\n    \"status\" TEXT,\\n    \"health\" text COLLATE \"pg_catalog\".\"default\",\\n    \"spc_common\" text COLLATE \"pg_catalog\".\"default\",\\n    \"geometry\" geometry(POINT, 3857)\\n);\\n\\nCREATE TABLE IF NOT EXISTS zillow (\\n  \"index\" int8 PRIMARY KEY,\\n  \"RegionID\" int8,\\n  \"RegionName\" int8,\\n  \"date\" DATE,\\n  \"rent\" float8\\n)\\n;\\n\\nCREATE TABLE IF NOT EXISTS Bedbug (\\n  \"index\" int   PRIMARY KEY,\\n  \"Building ID\" int8,\\n  \"Postcode\" int8,\\n  \"Filing Date\" timestamp(6),\\n  \"Eradicated Unit Count\" float8,\\n  \"Re-infested  Dwelling Unit Count\" float8,\\n  \"Latitude\" float8,\\n  \"Longitude\" float8,\\n  \"geometry\" geometry(POINT,3857)\\n);\\n'"
     ]
    }
   ],
   "source": [
    "# # Read the SQL schema file\n",
    "# schema_file_path= \"schema.sql\"\n",
    "# with open(schema_file_path, 'r') as file:\n",
    "#     schema_sql = file.read()\n",
    "# \n",
    "# # Execute the SQL schema\n",
    "# with engine.connect() as connection:\n",
    "#     # It's often a good idea to execute commands within a transaction\n",
    "#     with connection.begin() as transaction:\n",
    "#         try:\n",
    "#             connection.execute(schema_sql)\n",
    "#             # Commit the transaction if all commands execute successfully\n",
    "#             transaction.commit()\n",
    "#         except Exception as e:\n",
    "#             # Rollback the transaction in case of an error\n",
    "#             transaction.rollback()\n",
    "#             # Optionally, re-raise the exception or handle it as needed\n",
    "#             raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-10T17:42:35.772076Z",
     "start_time": "2023-12-10T17:42:35.740032Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "       index  RegionID  RegionName        date         rent\n0          0     62093       11385  2015-01-31          NaN\n1          1     62019       11208  2015-01-31          NaN\n2          2     62046       11236  2015-01-31          NaN\n3          3     61807       10467  2015-01-31          NaN\n4          4     62085       11373  2015-01-31          NaN\n...      ...       ...         ...         ...          ...\n15325  15325     61773       10282  2023-09-30  7347.458333\n15326  15326     62010       11109  2023-09-30  4529.358974\n15327  15327     61620       10006  2023-09-30  4060.096154\n15328  15328     61723       10162  2023-09-30  5011.666667\n15329  15329     61618       10004  2023-09-30  4355.328283\n\n[15330 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>RegionID</th>\n      <th>RegionName</th>\n      <th>date</th>\n      <th>rent</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>62093</td>\n      <td>11385</td>\n      <td>2015-01-31</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>62019</td>\n      <td>11208</td>\n      <td>2015-01-31</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>62046</td>\n      <td>11236</td>\n      <td>2015-01-31</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>61807</td>\n      <td>10467</td>\n      <td>2015-01-31</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>62085</td>\n      <td>11373</td>\n      <td>2015-01-31</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>15325</th>\n      <td>15325</td>\n      <td>61773</td>\n      <td>10282</td>\n      <td>2023-09-30</td>\n      <td>7347.458333</td>\n    </tr>\n    <tr>\n      <th>15326</th>\n      <td>15326</td>\n      <td>62010</td>\n      <td>11109</td>\n      <td>2023-09-30</td>\n      <td>4529.358974</td>\n    </tr>\n    <tr>\n      <th>15327</th>\n      <td>15327</td>\n      <td>61620</td>\n      <td>10006</td>\n      <td>2023-09-30</td>\n      <td>4060.096154</td>\n    </tr>\n    <tr>\n      <th>15328</th>\n      <td>15328</td>\n      <td>61723</td>\n      <td>10162</td>\n      <td>2023-09-30</td>\n      <td>5011.666667</td>\n    </tr>\n    <tr>\n      <th>15329</th>\n      <td>15329</td>\n      <td>61618</td>\n      <td>10004</td>\n      <td>2023-09-30</td>\n      <td>4355.328283</td>\n    </tr>\n  </tbody>\n</table>\n<p>15330 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_zillow_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T17:46:47.430168Z",
     "start_time": "2023-12-10T17:46:43.350555Z"
    }
   },
   "outputs": [],
   "source": [
    "df_zillow_data.to_sql('zillow', engine, if_exists='append', index=False)\n",
    "df_bedbug_data.to_postgis('bedbug', engine, if_exists='append', index=False)\n",
    "geodf_zipcode_data.to_postgis('nyc_shape', engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-12-10T17:46:52.536284Z"
    }
   },
   "outputs": [],
   "source": [
    "geodf_311_data.to_postgis('t311', engine, if_exists='append', index=False)\n",
    "geodf_tree_data.to_postgis('stc', engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-10T17:24:30.312783Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Understanding the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "tags": [],
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Helper function to write the queries to file\n",
    "import os\n",
    "\n",
    "\n",
    "def write_query_to_file(query: str, outfile: str) -> None:\n",
    "    \"\"\"\n",
    "    Writes a given query string to a specified file.\n",
    "\n",
    "    Args:\n",
    "    query (str): The query string to write to the file.\n",
    "    outfile (str): The file path where the query will be written.\n",
    "\n",
    "    Creates the directory for the outfile if it doesn't exist and writes the query to the file.\n",
    "    \"\"\"\n",
    "    # Create the directory for outfile if it doesn't exist\n",
    "    os.makedirs(os.path.dirname(outfile), exist_ok=True)\n",
    "\n",
    "    # Open the file and write the query\n",
    "    with open(outfile, 'w') as file:\n",
    "        file.write(query)\n",
    "\n",
    "# Assert test case\n",
    "test_query = \"SELECT * FROM table;\"\n",
    "test_outfile = \"/tmp/test_query.sql\"\n",
    "\n",
    "# Execute the function with the test query and outfile\n",
    "write_query_to_file(test_query, test_outfile)\n",
    "\n",
    "# Verify the content of the written file\n",
    "with open(test_outfile, 'r') as file:\n",
    "    content = file.read()\n",
    "assert content == test_query, \"Test case failed: The content of the file does not match the query\"\n",
    "\n",
    "# Note: This test case writes to a temporary file. Ensure the file path is appropriate for your environment.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "tags": [],
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "\n",
    "QUERY_1_FILENAME = \"query/area_more_clam.sql\"\n",
    "\n",
    "QUERY_1 = \"\"\"\n",
    "SELECT \"Incident Zip\", COUNT(*) AS number_of_complaints\n",
    "FROM t311\n",
    "WHERE \"Created Date\" BETWEEN '2022-10-01' AND '2023-09-30'\n",
    "GROUP BY \"Incident Zip\"\n",
    "ORDER BY number_of_complaints DESC;\n",
    "\"\"\"\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(QUERY_1))\n",
    "    for row in result:\n",
    "        print(row)\n",
    "write_query_to_file(QUERY_1, QUERY_1_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, the area with the zip code 11226 might be more calm to live in, since we found that 11226 has the largest number of 311 complaints in between October 1st, 2022 and September 30th, 2023 (inclusive), which is 48333. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "tags": [],
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "QUERY_2_FILENAME = \"query/most_greenary.sql\"\n",
    "\n",
    "QUERY_2 = \"\"\"\n",
    "SELECT zipcode, COUNT(*) AS total_trees\n",
    "FROM stc\n",
    "GROUP BY zipcode\n",
    "ORDER BY total_trees DESC\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(QUERY_2))\n",
    "    for row in result:\n",
    "        print(row)\n",
    "write_query_to_file(QUERY_2, QUERY_2_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 10 areas with the zip codes 10312, 10314, 10306, 10309, 11234, 11385, 11357, 11207, 11208, 11434 have the most trees, which are more greenery than the others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "tags": [],
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "QUERY_3_FILENAME = \"query/most_trees_affordability.sql\"\n",
    "\n",
    "QUERY_3 = \"\"\"\n",
    "select zillow.\"RegionName\" , TO_CHAR(AVG(zillow.rent), 'FM999,999,990.00') as avg_price\n",
    "from zillow inner join (\n",
    "SELECT zipcode, COUNT(*) AS total_trees\n",
    "FROM stc\n",
    "GROUP BY zipcode\n",
    "ORDER BY total_trees DESC\n",
    "LIMIT 10\n",
    ") t on t.zipcode = zillow.\"RegionName\"\n",
    "where zillow.date >= '2023-08-01'\n",
    "and zillow.date < '2023-09-01'\n",
    "group by zillow.\"RegionName\"\n",
    "order by avg_price desc;\n",
    "\n",
    "\"\"\"\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(QUERY_3))\n",
    "    for row in result:\n",
    "        print(row)\n",
    "write_query_to_file(QUERY_3, QUERY_3_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average rent costs for area with zip code 11207, 11385, 11208, 11434, 10314, 11357, 10306, 10309, 10312 are 3079.09, 3064.48, 2737.55, 2645.92, 2465.47, 2458.81, 2331.54, 2312.31, 1832.01, 1775.09 respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "tags": [],
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "QUERY_4_FILENAME = \"query/most_trees_affordability.sql\"\n",
    "\n",
    "QUERY_4 = \"\"\"\n",
    "(select zillow.\"RegionName\" , avg(zillow.rent) as avg_price , count(tree_id) as tree_numebr\n",
    ", count(t311.\"Unique Key\") as compaint_number\n",
    "from zillow\n",
    "inner join stc on zillow.\"RegionName\" = stc.zipcode\n",
    "inner join t311 on t311.\"Incident Zip\" = zillow.\"RegionName\"\n",
    "where zillow.date >= '2023-01-01'\n",
    "and zillow.date < '2023-02-01'\n",
    "and t311.\"Created Date\">= '2023-01-01'\n",
    "and t311.\"Created Date\"< '2023-02-01'\n",
    "and stc.created_at< '2023-02-01'\n",
    "group by zillow.\"RegionName\"\n",
    "HAVING avg(zillow.rent) is not NULL\n",
    "order by avg_price desc limit 5)\n",
    "union\n",
    "(select zillow.\"RegionName\" , avg(zillow.rent) as avg_price , count(tree_id) as tree_numebr\n",
    ", count(t311.\"Unique Key\") as compaint_number\n",
    "from zillow\n",
    "inner join stc on zillow.\"RegionName\" = stc.zipcode\n",
    "inner join t311 on t311.\"Incident Zip\" = zillow.\"RegionName\"\n",
    "where zillow.date >= '2023-01-01'\n",
    "and zillow.date < '2023-02-01'\n",
    "and t311.\"Created Date\">= '2023-01-01'\n",
    "and t311.\"Created Date\"< '2023-02-01'\n",
    "and stc.created_at< '2023-02-01'\n",
    "group by zillow.\"RegionName\"\n",
    "HAVING avg(zillow.rent) is not NULL\n",
    "order by avg_price ASC limit 5)\n",
    "\"\"\"\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(QUERY_3))\n",
    "    for row in result:\n",
    "        print(row)\n",
    "write_query_to_file(QUERY_4, QUERY_4_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the month of January 2023, the 5 zip codes with the lowest average rent are 10309, 10453, 10462, 11357, 10458 respectively, and 5 zipcodes of the highest average rent are 10013, 10282, 10069, 10011, 10007 respectively, the highest average rents do not correlate directly with the number of trees or complaints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "QUERY_5_FILENAME = \"query/most_greenery_v2.sql\"\n",
    "\n",
    "QUERY_5 = \"\"\"\n",
    "SELECT\n",
    "    nyc_shape.\"ZIPCODE\",\n",
    "    COUNT(stc.tree_id) as TreeCount\n",
    "FROM\n",
    "    nyc_shape\n",
    "JOIN\n",
    "    stc\n",
    "on st_within(stc.geometry,nyc_shape.geometry)\n",
    "GROUP BY\n",
    "    nyc_shape.\"ZIPCODE\"\n",
    "ORDER BY\n",
    "    TreeCount DESC\n",
    "LIMIT 10;\n",
    "\n",
    "\"\"\"\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(QUERY_5))\n",
    "    for row in result:\n",
    "        print(row)\n",
    "write_query_to_file(QUERY_5, QUERY_5_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same as query 2, the 10 areas with the zip codes 10312, 10314, 10306, 10309, 11234, 11385, 11357, 11207, 11208, 11434 have the most trees, which are more greenery than the others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## query 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "QUERY_6_FILENAME = \"query/immediate_area.sql\"\n",
    "\n",
    "QUERY_6 = \"\"\"\n",
    "SELECT\n",
    "    stc.tree_id AS \"ID\",\n",
    "    stc.spc_common AS \"species\",\n",
    "    stc.health,\n",
    "    stc.status,\n",
    "    ST_AsText(stc.geometry) AS \"coordinate location\"\n",
    "FROM\n",
    "    stc\n",
    "WHERE\n",
    "    ST_DWithin(\n",
    "        stc.geometry,\n",
    "        ST_Transform(ST_SetSRID(ST_Point(-73.96253174434912, 40.80737875669467), 4326), 3857),\n",
    "        804.7\n",
    "    );\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(QUERY_6))\n",
    "    for row in result:\n",
    "        print(row)\n",
    "write_query_to_file(QUERY_6, QUERY_6_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This query summarizes the trees that are within 0.5 mile radius of the point with latitude: 40.80737875669467 and longitude: -73.96253174434912."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 4: Visualizing the Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visulization 1:What can I expect to put up with in NYC?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "\n",
    "def get_data_for_daily_complaints():\n",
    "    # Database connection parameters\n",
    "    host = \"localhost\"\n",
    "    dbname = \"e4501project\"\n",
    "    user = \"postgres\"\n",
    "    password = \"1234\"\n",
    "\n",
    "    # Connect to the database\n",
    "    conn = psycopg2.connect(host=host, dbname=dbname, user=user, password=password)\n",
    "\n",
    "    # Query to find the top 3 complaint types\n",
    "    top_complaints_query = \"\"\"\n",
    "    SELECT\n",
    "        \"Complaint Type\"\n",
    "    FROM\n",
    "        t311\n",
    "    WHERE\n",
    "        \"Created Date\" >= '2022-10-01' AND \"Created Date\" <= '2023-09-30'\n",
    "    GROUP BY\n",
    "        \"Complaint Type\"\n",
    "    ORDER BY\n",
    "        COUNT(\"Unique Key\") DESC\n",
    "    LIMIT 3;\n",
    "    \"\"\"\n",
    "\n",
    "    # Execute the top complaints query\n",
    "    top_complaints_df = pd.read_sql_query(top_complaints_query, conn)\n",
    "    top_complaints = top_complaints_df['Complaint Type'].tolist()\n",
    "\n",
    "    # Query to get daily counts for the top 3 complaint types\n",
    "    daily_counts_query = f\"\"\"\n",
    "    SELECT\n",
    "        \"Complaint Type\",\n",
    "        DATE(\"Created Date\") as Date,\n",
    "        COUNT(\"Unique Key\") AS Daily_Count\n",
    "    FROM\n",
    "        t311\n",
    "    WHERE\n",
    "        \"Complaint Type\" IN %s AND\n",
    "        \"Created Date\" >= '2022-10-01' AND\n",
    "        \"Created Date\" <= '2023-09-30'\n",
    "    GROUP BY\n",
    "        \"Complaint Type\", DATE(\"Created Date\")\n",
    "    ORDER BY\n",
    "        Date;\n",
    "    \"\"\"\n",
    "\n",
    "    # Execute the daily counts query\n",
    "    daily_counts_df = pd.read_sql_query(daily_counts_query, conn, params=(tuple(top_complaints),))\n",
    "    daily_counts_df['date'] = pd.to_datetime(daily_counts_df['date'])\n",
    "\n",
    "    # Close the database connection\n",
    "    conn.close()\n",
    "\n",
    "    return daily_counts_df\n",
    "\n",
    "daily_complaints_df = get_data_for_daily_complaints()\n",
    "\n",
    "# Assert that the DataFrame is not empty\n",
    "assert not daily_complaints_df.empty, \"DataFrame should not be empty.\"\n",
    "\n",
    "# Assert that the DataFrame has the expected columns\n",
    "expected_columns = {'Complaint Type', 'daily_count', 'date'}\n",
    "assert set(daily_complaints_df.columns) == set(expected_columns), \\\n",
    "    \"DataFrame should contain the columns: 'Complaint Type', 'date', 'Daily_Count'.\"\n",
    "\n",
    "# Assert that the column data types are as expected\n",
    "assert pd.api.types.is_datetime64_any_dtype(daily_complaints_df['date']), \\\n",
    "    \"Column 'Date' should be of datetime type.\"\n",
    "assert pd.api.types.is_numeric_dtype(daily_complaints_df['daily_count']), \\\n",
    "    \"Column 'Daily_Count' should be numeric.\""
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def create_animation(df: DataFrame) -> FuncAnimation:\n",
    "    \"\"\"\n",
    "    Creates an animated bar chart for daily complaint data.\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): A DataFrame containing 'date', 'Complaint Type', and 'daily_count' columns.\n",
    "\n",
    "    Returns:\n",
    "        FuncAnimation: An animation object representing the animated bar chart.\n",
    "    \"\"\"\n",
    "\n",
    "    required_columns = {'date', 'Complaint Type', 'daily_count'}\n",
    "    assert set(df.columns) >= required_columns, \"DataFrame lacks required columns for animation.\"\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    unique_dates = df['date'].unique()\n",
    "\n",
    "    def animate(i):\n",
    "        \"\"\"\n",
    "        Update function for the animation, showing cumulative complaints up to each date.\n",
    "        \"\"\"\n",
    "        ax.clear()\n",
    "        current_date = unique_dates[i]\n",
    "        current_date_py = pd.to_datetime(current_date).to_pydatetime()\n",
    "\n",
    "        filtered_df = df[df['date'] <= current_date]\n",
    "        complaint_counts = filtered_df.groupby('Complaint Type')['daily_count'].sum()\n",
    "\n",
    "        ax.bar(complaint_counts.index, complaint_counts.values, color=['blue', 'green', 'red'])\n",
    "        ax.set_xlabel('Complaint Type')\n",
    "        ax.set_ylabel('Cumulative Number of Complaints')\n",
    "        ax.set_title(f'Complaints up to {current_date_py.strftime(\"%Y-%m-%d\")}')\n",
    "        plt.xticks(rotation=0)\n",
    "\n",
    "    ani = animation.FuncAnimation(fig, animate, frames=len(unique_dates), repeat=False)\n",
    "    return ani\n",
    "\n",
    "daily_complaints_df = get_data_for_daily_complaints()\n",
    "ani = create_animation(daily_complaints_df)\n",
    "\n",
    "assert isinstance(ani, FuncAnimation), \"The function should return a FuncAnimation object.\"\n",
    "HTML(ani.to_jshtml())\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visulization 2:What are the most common complaints in the immediate area?\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "from pandas import DataFrame\n",
    "\n",
    "def get_data_for_complaints_10027() -> DataFrame:\n",
    "    \"\"\"\n",
    "    Retrieves the top 10 complaint types for ZIP code 10027 from a PostgreSQL database.\n",
    "\n",
    "    The function connects to the database, executes a query to find the top 10 complaint types in the specified ZIP code\n",
    "    and time frame, and then returns this data as a DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: A DataFrame containing the top 10 complaint types and their counts.\n",
    "    \"\"\"\n",
    "\n",
    "    # Database connection parameters\n",
    "    host = \"localhost\"\n",
    "    dbname = \"e4501project\"\n",
    "    user = \"postgres\"\n",
    "    password = \"1234\"\n",
    "\n",
    "    # Connect to the database\n",
    "    conn = psycopg2.connect(host=host, dbname=dbname, user=user, password=password)\n",
    "\n",
    "    # Query to find the top 10 complaint types in ZIP code 10027\n",
    "    complaints_10027_query = \"\"\"\n",
    "    SELECT\n",
    "        \"Complaint Type\",\n",
    "        COUNT(\"Unique Key\") AS NumberOfComplaints\n",
    "    FROM\n",
    "        t311\n",
    "    WHERE\n",
    "        \"Incident Zip\" = 10027 AND\n",
    "        \"Created Date\" BETWEEN '2018-10-01' AND '2023-09-30'\n",
    "    GROUP BY\n",
    "        \"Complaint Type\"\n",
    "    ORDER BY\n",
    "        NumberOfComplaints DESC\n",
    "    LIMIT 10;\n",
    "    \"\"\"\n",
    "\n",
    "    # Execute the query and retrieve the data\n",
    "    top_complaints_df = pd.read_sql_query(complaints_10027_query, conn)\n",
    "\n",
    "    # Close the database connection\n",
    "    conn.close()\n",
    "\n",
    "    return top_complaints_df\n",
    "\n",
    "complaints_df = get_data_for_complaints_10027()\n",
    "\n",
    "# Assert that the DataFrame is not empty\n",
    "assert not complaints_df.empty, \"DataFrame should not be empty.\"\n",
    "\n",
    "# Assert that the DataFrame has the expected columns\n",
    "expected_columns = {'Complaint Type', 'numberofcomplaints'}\n",
    "assert set(complaints_df.columns) == expected_columns, \"DataFrame should have 'Complaint Type' and 'NumberOfComplaints' columns.\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def complaints_10027_figure(df: DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Generates a horizontal bar chart for the top 10 complaint types in ZIP code 10027.\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): A DataFrame containing 'Complaint Type' and 'numberofcomplaints' columns.\n",
    "\n",
    "    The function creates a bar chart displaying the number of complaints for each complaint type.\n",
    "    \"\"\"\n",
    "\n",
    "    # Assert that the DataFrame has the required columns\n",
    "    required_columns = {'Complaint Type', 'numberofcomplaints'}\n",
    "    assert set(df.columns) >= required_columns, \"DataFrame lacks required columns for the chart.\"\n",
    "\n",
    "    # Creating the bar chart\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(df['Complaint Type'], df['numberofcomplaints'], color='skyblue')\n",
    "    plt.xlabel('Number of Complaints')\n",
    "    plt.title('Top 10 Complaint Types in Zip Code 10027 (Oct 1, 2018 - Sep 30, 2023)')\n",
    "    plt.show()\n",
    "\n",
    "df_10027 = get_data_for_complaints_10027()\n",
    "complaints_10027_figure(df_10027)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visulization 3:  Is there any correlation between rent, trees, and complaints at all?\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "from pandas import DataFrame\n",
    "\n",
    "def get_data_for_correlation() -> DataFrame:\n",
    "    \"\"\"\n",
    "    Retrieves and merges rent, tree, and complaint data from a PostgreSQL database for correlation analysis.\n",
    "\n",
    "    The function connects to the database, executes queries to retrieve rent data, tree data, and complaint data,\n",
    "    and then merges these datasets on the 'zipcode' column.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: A DataFrame containing merged rent, tree, and complaint data.\n",
    "    \"\"\"\n",
    "\n",
    "    # Database connection parameters\n",
    "    host = \"localhost\"\n",
    "    dbname = \"e4501project\"\n",
    "    user = \"postgres\"\n",
    "    password = \"1234\"\n",
    "\n",
    "    # Connect to the database\n",
    "    conn = psycopg2.connect(host=host, dbname=dbname, user=user, password=password)\n",
    "\n",
    "    # Queries to retrieve data\n",
    "    rent_data_query = \"\"\"\n",
    "        SELECT\n",
    "            \"RegionName\" as ZipCode,\n",
    "            AVG(rent) as AverageRent\n",
    "        FROM\n",
    "            zillow\n",
    "        WHERE\n",
    "            date >= '2015-01-01' AND date <= '2023-09-30'\n",
    "        GROUP BY\n",
    "            \"RegionName\";\n",
    "    \"\"\"\n",
    "\n",
    "    Tree_Data_query = \"\"\"\n",
    "    SELECT\n",
    "        zipcode,\n",
    "        COUNT(tree_id) as NumberOfTrees\n",
    "    FROM\n",
    "        stc\n",
    "    GROUP BY\n",
    "        zipcode;\n",
    "    \"\"\"\n",
    "\n",
    "    Complaint_Data_query = \"\"\"\n",
    "    SELECT\n",
    "        \"Incident Zip\" as ZipCode,\n",
    "        COUNT(\"Unique Key\") as NumberOfComplaints\n",
    "    FROM\n",
    "        t311\n",
    "    WHERE\n",
    "        \"Created Date\" >= '2015-01-01' AND \"Created Date\" <= '2023-09-30'\n",
    "    GROUP BY\n",
    "        \"Incident Zip\";\n",
    "    \"\"\"\n",
    "\n",
    "    # Execute the queries and retrieve the data\n",
    "    rent_data_df = pd.read_sql_query(rent_data_query, conn)\n",
    "    Tree_Data_df = pd.read_sql_query(Tree_Data_query, conn)\n",
    "    Complaint_Data_df = pd.read_sql_query(Complaint_Data_query, conn)\n",
    "\n",
    "    # Merging the data on 'zipcode'\n",
    "    merged_data = pd.merge(rent_data_df, Tree_Data_df, on='zipcode', how='inner')\n",
    "    merged_data = pd.merge(merged_data, Complaint_Data_df, on='zipcode', how='inner')\n",
    "\n",
    "    # Close the database connection\n",
    "    conn.close()\n",
    "\n",
    "    return merged_data\n",
    "\n",
    "correlation_data_df = get_data_for_correlation()\n",
    "\n",
    "# Assert that the DataFrame is not empty\n",
    "assert not correlation_data_df.empty, \"DataFrame should not be empty.\"\n",
    "\n",
    "# Assert that the DataFrame has the expected columns\n",
    "expected_columns = {'averagerent', 'numberofcomplaints', 'numberoftrees', 'zipcode'}\n",
    "assert set(correlation_data_df.columns) == expected_columns, \"DataFrame should have the expected columns for correlation analysis.\""
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import DataFrame\n",
    "\n",
    "def genertate_plot(df: DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Generates scatter plots showing relationships between average rent and number of trees,\n",
    "    and average rent and number of complaints, by ZIP code.\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): A DataFrame containing 'averagerent', 'numberoftrees', and 'numberofcomplaints' columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Assert that the DataFrame has the required columns\n",
    "    required_columns = {'averagerent', 'numberoftrees', 'numberofcomplaints'}\n",
    "    assert set(df.columns) >= required_columns, \"DataFrame lacks required columns for the plot.\"\n",
    "\n",
    "    # Creating the scatter plots\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8), sharex=True)\n",
    "\n",
    "    # Rent vs Number of Trees\n",
    "    ax1.scatter(df['averagerent'], df['numberoftrees'], color='green')\n",
    "    ax1.set_ylabel('Number of Trees')\n",
    "    ax1.set_title('Rent vs Trees and Complaints by Zip Code')\n",
    "\n",
    "    # Rent vs Number of Complaints\n",
    "    ax2.scatter(df['averagerent'], df['numberofcomplaints'], color='red')\n",
    "    ax2.set_xlabel('Average Rent')\n",
    "    ax2.set_ylabel('Number of Complaints')\n",
    "\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "merged_data  = get_data_for_correlation()\n",
    "print(merged_data)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "genertate_plot(merged_data)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visulization 4:  If I can afford more in rent, will there be fewer issues & complaints?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "from pandas import DataFrame\n",
    "\n",
    "def get_merged_data() -> DataFrame:\n",
    "    \"\"\"\n",
    "    Retrieves and merges rent and complaint data from a PostgreSQL database.\n",
    "\n",
    "    The function connects to the database, executes queries to retrieve rent data and complaint data,\n",
    "    and then merges these datasets on the 'ZipCode' column.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: A DataFrame containing merged rent and complaint data.\n",
    "    \"\"\"\n",
    "\n",
    "    # Database connection parameters\n",
    "    host = \"localhost\"\n",
    "    dbname = \"e4501project\"\n",
    "    user = \"postgres\"\n",
    "    password = \"1234\"\n",
    "\n",
    "    # SQL queries to fetch rent data and complaint data\n",
    "    rent_query = \"\"\"\n",
    "    SELECT\n",
    "        \"RegionName\" AS ZipCode,\n",
    "        AVG(rent) AS AverageRent\n",
    "    FROM\n",
    "        zillow\n",
    "    WHERE\n",
    "        date BETWEEN '2023-09-01' AND '2023-09-30'\n",
    "    GROUP BY\n",
    "        \"RegionName\";\n",
    "    \"\"\"\n",
    "\n",
    "    complaints_query = \"\"\"\n",
    "    SELECT\n",
    "        \"Incident Zip\" AS ZipCode,\n",
    "        COUNT(\"Unique Key\") AS NumberOfComplaints\n",
    "    FROM\n",
    "        t311\n",
    "    WHERE\n",
    "        \"Created Date\" BETWEEN '2022-10-01' AND '2023-09-30'\n",
    "    GROUP BY\n",
    "        \"Incident Zip\";\n",
    "    \"\"\"\n",
    "\n",
    "    # Connect to the database\n",
    "    conn = psycopg2.connect(host=host, dbname=dbname, user=user, password=password)\n",
    "\n",
    "    # Execute queries and fetch data\n",
    "    rent_data = pd.read_sql_query(rent_query, conn)\n",
    "    complaints_data = pd.read_sql_query(complaints_query, conn)\n",
    "\n",
    "    # Merge the data on ZipCode\n",
    "    merged_data = pd.merge(rent_data, complaints_data, on='zipcode', how='inner')\n",
    "\n",
    "    # Close the database connection\n",
    "    conn.close()\n",
    "\n",
    "    return merged_data\n",
    "merged_df = get_merged_data()\n",
    "\n",
    "# Assert that the DataFrame is not empty\n",
    "assert not merged_df.empty, \"Merged DataFrame should not be empty.\"\n",
    "\n",
    "# Assert that the DataFrame has the expected columns\n",
    "expected_columns = {'zipcode', 'averagerent', 'numberofcomplaints'}\n",
    "assert set(merged_df.columns) == expected_columns, \"Merged DataFrame should contain 'ZipCode', 'AverageRent', and 'NumberOfComplaints'.\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "get_merged_data().columns"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import DataFrame\n",
    "\n",
    "def create_plot(data: DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Generates a box plot to visualize the relationship between average rent and the number of 311 complaints.\n",
    "\n",
    "    Parameters:\n",
    "        data (DataFrame): A DataFrame containing 'averagerent' and 'numberofcomplaints' columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Assert that the DataFrame has the required columns\n",
    "    required_columns = {'averagerent', 'numberofcomplaints'}\n",
    "    assert set(data.columns) >= required_columns, \"DataFrame lacks required columns for the plot.\"\n",
    "\n",
    "    # Creating rent bins for categorization\n",
    "    rent_bins = range(0, int(data['averagerent'].max()) + 1000, 1000)\n",
    "    rent_labels = [f\"${i}-${i + 999}\" for i in rent_bins[:-1]]\n",
    "    data['RentBin'] = pd.cut(data['averagerent'], bins=rent_bins, labels=rent_labels, right=False)\n",
    "\n",
    "    # Preparing data for the boxplot\n",
    "    boxplot_data = [group['numberofcomplaints'].values for _, group in data.groupby('RentBin')]\n",
    "\n",
    "    # Creating the boxplot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.boxplot(boxplot_data, labels=rent_labels)\n",
    "    plt.xlabel('Average Rent (in bins)')\n",
    "    plt.ylabel('Number of 311 Complaints')\n",
    "    plt.title('Number of 311 Complaints vs. Average Rent by Zip Code (Oct 1, 2022 - Sep 30, 2023)')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Call the function to create the plot\n",
    "merged_data = get_merged_data()\n",
    "create_plot(merged_data)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visulization 5:  Where were the recent 311 incidents reported from in the immediate area?\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "from pandas import DataFrame\n",
    "\n",
    "def get_311_incidents_data() -> DataFrame:\n",
    "    \"\"\"\n",
    "    Retrieves 311 incident data (latitude and longitude) from a PostgreSQL database.\n",
    "\n",
    "    The function connects to the database, executes a query to retrieve incident data\n",
    "    within a specific radius of a given point, and then returns this data as a DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: A DataFrame containing the latitude and longitude of 311 incidents.\n",
    "    \"\"\"\n",
    "\n",
    "    # Database connection parameters\n",
    "    host = \"localhost\"\n",
    "    dbname = \"e4501project\"\n",
    "    user = \"postgres\"\n",
    "    password = \"1234\"\n",
    "\n",
    "    # SQL query to fetch 311 incident data\n",
    "    incidents_query = \"\"\"\n",
    "    SELECT\n",
    "        \"Latitude\",\n",
    "        \"Longitude\"\n",
    "    FROM\n",
    "        t311\n",
    "    WHERE\n",
    "        \"Created Date\" BETWEEN '2023-01-01' AND '2023-09-30'\n",
    "        AND ST_DWithin(\n",
    "            ST_MakePoint(\"Longitude\", \"Latitude\")::geography,\n",
    "            ST_MakePoint(-73.96253174434912, 40.80737875669467)::geography,\n",
    "            1000\n",
    "        );\n",
    "    \"\"\"\n",
    "\n",
    "    # Connect to the database\n",
    "    conn = psycopg2.connect(host=host, dbname=dbname, user=user, password=password)\n",
    "\n",
    "    # Execute query and fetch data\n",
    "    incidents_data = pd.read_sql_query(incidents_query, conn)\n",
    "\n",
    "    # Close the database connection\n",
    "    conn.close()\n",
    "\n",
    "    return incidents_data\n",
    "\n",
    "incidents_df = get_311_incidents_data()\n",
    "\n",
    "# Assert that the DataFrame is not empty\n",
    "assert not incidents_df.empty, \"DataFrame should not be empty.\"\n",
    "\n",
    "# Assert that the DataFrame has the expected columns\n",
    "expected_columns = {'Latitude', 'Longitude'}\n",
    "assert set(incidents_df.columns) == expected_columns, \"DataFrame should contain 'Latitude' and 'Longitude' columns.\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import contextily as ctx\n",
    "from shapely.geometry import Point\n",
    "from pandas import DataFrame\n",
    "from geopandas import GeoDataFrame\n",
    "\n",
    "def plot_geospatial_data(df: DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Plots geospatial data from a DataFrame containing Latitude and Longitude columns.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): DataFrame containing the geospatial data with 'Latitude' and 'Longitude'.\n",
    "    \"\"\"\n",
    "\n",
    "    # Assert that the DataFrame has the required columns\n",
    "    required_columns = {'Latitude', 'Longitude'}\n",
    "    assert set(df.columns) >= required_columns, \"DataFrame lacks required columns for geospatial plotting.\"\n",
    "\n",
    "    # Convert DataFrame to GeoDataFrame with WGS 84 (EPSG:4326) CRS\n",
    "    gdf = gpd.GeoDataFrame(\n",
    "        df,\n",
    "        geometry=[Point(xy) for xy in zip(df.Longitude, df.Latitude)],\n",
    "        crs=\"EPSG:4326\"  # WGS 84 coordinate reference system\n",
    "    )\n",
    "\n",
    "    # Convert GeoDataFrame to Web Mercator (EPSG:3857) for mapping\n",
    "    gdf = gdf.to_crs(epsg=3857)\n",
    "\n",
    "    # Plotting\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    gdf.plot(ax=ax, color='red', markersize=5)\n",
    "\n",
    "    # Adding a basemap using contextily\n",
    "    ctx.add_basemap(ax, source=ctx.providers.OpenStreetMap.Mapnik, zoom='auto')\n",
    "\n",
    "    # Setting axis labels and adjusting axis limits\n",
    "    ax.set_xlabel('Longitude')\n",
    "    ax.set_ylabel('Latitude')\n",
    "    ax.set_xlim(gdf.total_bounds[[0, 2]])\n",
    "    ax.set_ylim(gdf.total_bounds[[1, 3]])\n",
    "\n",
    "    # Adding gridlines and title to the plot\n",
    "    ax.grid(True)\n",
    "    ax.set_title('Reported 311 Incidents (Jan 1, 2023 - Sep 30, 2023) within 1km Radius')\n",
    "\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "merge_data = get_311_incidents_data()\n",
    "merge_data\n",
    "plot_geospatial_data(merge_data)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visulization 6:  Are areas trying to improve the amount of trees in the neighborhood?\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "from pandas import DataFrame\n",
    "from typing import Tuple\n",
    "\n",
    "def get_trees_and_complaints_data() -> Tuple[DataFrame, DataFrame]:\n",
    "    \"\"\"\n",
    "    Retrieves trees data and 311 complaints data related to 'New Tree Request' from a PostgreSQL database.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[DataFrame, DataFrame]: Two DataFrames containing trees data and 311 complaints data.\n",
    "    \"\"\"\n",
    "\n",
    "    # Database connection parameters\n",
    "    host = \"localhost\"\n",
    "    dbname = \"e4501project\"\n",
    "    user = \"postgres\"\n",
    "    password = \"1234\"\n",
    "\n",
    "    # SQL query to fetch trees data\n",
    "    trees_query = \"\"\"\n",
    "    SELECT\n",
    "        \"Latitude\",\n",
    "        \"longitude\"\n",
    "    FROM\n",
    "        stc;\n",
    "    \"\"\"\n",
    "\n",
    "    # SQL query to fetch 311 complaints data\n",
    "    complaints_query = \"\"\"\n",
    "    SELECT\n",
    "        \"Latitude\",\n",
    "        \"Longitude\"\n",
    "    FROM\n",
    "        t311\n",
    "    WHERE\n",
    "        \"Complaint Type\" = 'New Tree Request'\n",
    "        AND \"Created Date\" BETWEEN '2018-10-01' AND '2023-09-30'\n",
    "        AND \"Latitude\" IS NOT NULL\n",
    "        AND \"Longitude\" IS NOT NULL;\n",
    "    \"\"\"\n",
    "\n",
    "    # Connect to the database\n",
    "    conn = psycopg2.connect(host=host, dbname=dbname, user=user, password=password)\n",
    "\n",
    "    # Execute queries and fetch data\n",
    "    trees_data = pd.read_sql_query(trees_query, conn)\n",
    "    complaints_data = pd.read_sql_query(complaints_query, conn)\n",
    "\n",
    "    # Close the database connection\n",
    "    conn.close()\n",
    "\n",
    "    return trees_data, complaints_data\n",
    "\n",
    "trees_df, complaints_df = get_trees_and_complaints_data()\n",
    "\n",
    "# Assert that both DataFrames are not empty\n",
    "assert not trees_df.empty, \"Trees DataFrame should not be empty.\"\n",
    "assert not complaints_df.empty, \"Complaints DataFrame should not be empty.\"\n",
    "\n",
    "# Assert that both DataFrames have the expected columns\n",
    "expected_columns_tree = {'Latitude', 'longitude'}\n",
    "assert set(trees_df.columns) == expected_columns_tree, \"Trees DataFrame should contain 'Latitude' and 'Longitude'.\"\n",
    "\n",
    "expected_columns = {'Latitude', 'Longitude'}\n",
    "assert set(complaints_df.columns) == expected_columns, \"Complaints DataFrame should contain 'Latitude' and 'Longitude'.\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import contextily as ctx\n",
    "from shapely.geometry import Point\n",
    "from pandas import DataFrame\n",
    "from geopandas import GeoDataFrame\n",
    "\n",
    "def plot_geospatial_data(trees_df: DataFrame, complaints_df: DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Plots geospatial data for trees and 311 new tree requests with a basemap.\n",
    "\n",
    "    Parameters:\n",
    "    trees_df (DataFrame): DataFrame containing tree data with 'Latitude' and 'Longitude'.\n",
    "    complaints_df (DataFrame): DataFrame containing 311 complaints data with 'Latitude' and 'Longitude'.\n",
    "    \"\"\"\n",
    "\n",
    "    # Assert that the DataFrames have the required columns\n",
    "    assert all(col in trees_df.columns for col in ['Latitude', 'longitude']), \\\n",
    "        \"Trees DataFrame lacks required columns 'Latitude' and 'Longitude'.\"\n",
    "    assert all(col in complaints_df.columns for col in ['Latitude', 'Longitude']), \\\n",
    "        \"Complaints DataFrame lacks required columns 'Latitude' and 'Longitude'.\"\n",
    "\n",
    "    # Convert DataFrames to GeoDataFrames with WGS 84 (EPSG:4326) CRS\n",
    "    gdf_trees = gpd.GeoDataFrame(\n",
    "        trees_df,\n",
    "        geometry=[Point(xy) for xy in zip(trees_df.longitude, trees_df.Latitude)],\n",
    "        crs=\"EPSG:4326\"\n",
    "    )\n",
    "    gdf_complaints = gpd.GeoDataFrame(\n",
    "        complaints_df,\n",
    "        geometry=[Point(xy) for xy in zip(complaints_df.Longitude, complaints_df.Latitude)],\n",
    "        crs=\"EPSG:4326\"\n",
    "    )\n",
    "\n",
    "    # Convert GeoDataFrames to Web Mercator (EPSG:3857) for mapping\n",
    "    gdf_trees = gdf_trees.to_crs(epsg=3857)\n",
    "    gdf_complaints = gdf_complaints.to_crs(epsg=3857)\n",
    "\n",
    "    # Plotting\n",
    "    fig, ax = plt.subplots(figsize=(12, 12))\n",
    "    gdf_trees.plot(ax=ax, color='green', markersize=5, label='Trees')\n",
    "    gdf_complaints.plot(ax=ax, color='red', markersize=5, label='New Tree Requests')\n",
    "\n",
    "    # Adding a basemap using contextily\n",
    "    ctx.add_basemap(ax, source=ctx.providers.OpenStreetMap.Mapnik)\n",
    "\n",
    "    # Setting axis labels and adding a legend\n",
    "    ax.set_xlabel('Longitude')\n",
    "    ax.set_ylabel('Latitude')\n",
    "    ax.set_title('NYC Trees and New Tree Requests (Oct 1, 2018 - Sep 30, 2023)')\n",
    "    ax.legend()\n",
    "\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tree,complaints_data = get_trees_and_complaints_data()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_geospatial_data(tree,complaints_data)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-10T17:07:44.243636Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-10T17:07:44.244355Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
